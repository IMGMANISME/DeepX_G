{"cells":[{"cell_type":"markdown","metadata":{"id":"-gZwlZ4layy9"},"source":["#專題資料結構\n","```\n","Project: DeepX\n","└─ original_dataset\n","   ├─ abnormal\n","   │   └─ abnormal_label\n","   │   └─ abnormal(.dcm)\n","   │   └─ abnormal(.jpg)\n","   ├─ normal\n","   │   └─ normal_label\n","   │   └─ normal(.dcm)\n","   │   └─ normal(.jpg)\n","└─ processed_dataset\n","   ├─ abnormal\n","   ├─ normal\n","└─ splitted_dataset\n","   ├─ test\n","   │   └─ abnormal\n","   │   └─ normal\n","   ├─ train\n","   │   └─ abnormal\n","   │   └─ normal\n","   ├─ train_argumentation\n","   │   └─ abnormal\n","   │   └─ normal\n","└─ tensor\n","   ├─ test\n","   ├─ train\n","└─ result\n","```"]},{"cell_type":"markdown","metadata":{"id":"n8YuhhVNSL48"},"source":["#連結Google drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20884,"status":"ok","timestamp":1697350320107,"user":{"displayName":"陳均葦","userId":"12397795912524578037"},"user_tz":-480},"id":"kDtbJAbS201N","outputId":"a3994609-178a-49d8-dd0e-e758c401dbee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":493,"status":"ok","timestamp":1697350320598,"user":{"displayName":"陳均葦","userId":"12397795912524578037"},"user_tz":-480},"id":"sfinzBRi27yj","outputId":"79713951-bb0d-4ba6-ae0e-6ef14eac8458"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['SEResNet.py',\n"," '.DS_Store',\n"," 'tensor',\n"," 'processed_dataset',\n"," 'splitted_dataset',\n"," 'result',\n"," 'original_dataset']"]},"metadata":{},"execution_count":2}],"source":["import os\n","os.chdir('/content/drive/My Drive/Deep_X_torch') #切換目錄\n","os.listdir() #確認目錄內容"]},{"cell_type":"markdown","metadata":{"id":"Pd2urWFtRs2f"},"source":["#將DCM檔轉成JPG檔"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8464,"status":"ok","timestamp":1695270884310,"user":{"displayName":"陳均葦","userId":"12397795912524578037"},"user_tz":-480},"id":"DTcpC-wJSoOc","outputId":"8af80904-9914-40cf-e651-e3ee9c152972"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.3)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"]}],"source":["!pip install pydicom\n","!pip install opencv-python"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5538,"status":"ok","timestamp":1695272937083,"user":{"displayName":"陳均葦","userId":"12397795912524578037"},"user_tz":-480},"id":"o3YCwVLTW7YD","outputId":"a035e2d7-ae26-4ce4-ff41-c9fdf1046ced"},"outputs":[{"name":"stdout","output_type":"stream","text":["test\n","File numbers:4\n","Elbow numbers: 4\n"]}],"source":["from itertools import count\n","import pydicom\n","import cv2\n","import os\n","\n","def dcm_to_png(folder_path,output_path,output_name):\n","    count = 1\n","    file_count = 0\n","    elbow_count = 0\n","    for file_name in os.listdir(folder_path):\n","        if file_name.endswith(\".dcm\"):\n","            file_count += 1\n","            try:\n","                ds = pydicom.dcmread(os.path.join(folder_path, file_name))\n","                # 檢索患者年齡\n","                patient_name = ds.PatientName\n","                uid = ds.SeriesInstanceUID\n","                patient_age = ds.PatientAge\n","                patient_part = ds.BodyPartExamined\n","\n","                if patient_part == \"ELBOW\":\n","                  elbow_count += 1\n","\n","                # 打印患者年齡\n","                # print(\"Filename:\",file_name)\n","                # print(\"classified:\",output_name)\n","                # print(\"Patient's Name:\", patient_name)\n","                # print(\"UID:\", uid)\n","                # print(\"Patient's Age:\", patient_age)\n","                # print(\"Patient's body part:\", patient_part)\n","                # print(\"\\n\\n\")\n","            except pydicom.errors.InvalidDicomError:\n","                continue\n","\n","            data = ds.pixel_array\n","            image = cv2.normalize(data, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","\n","            # calculate the rotation matrix\n","            rotation_matrix = cv2.getRotationMatrix2D((image.shape[1]/2, image.shape[0]/2), 0, 1.0)\n","\n","            # apply the rotation matrix to the image\n","            rotated = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]))\n","\n","            # adjust the brightness of the rotated image\n","            bright_image = cv2.convertScaleAbs(rotated, alpha=1, beta=0)\n","\n","            # create a new folder for each PNG image\n","            folder_name = os.path.join(os.getcwd(), output_path, output_name + \"(.jpg)\")\n","            os.makedirs(folder_name, exist_ok=True)\n","\n","            # save the enhanced image as a PNG file inside the folder\n","            file_prefix = os.path.splitext(file_name)[0]\n","            cv2.imwrite(os.path.join(folder_name, f\"{output_name}_{count}.jpg\"), bright_image)\n","            count += 1\n","\n","    print(output_name)\n","    print(\"File numbers:\" + str(file_count))\n","    print(\"Elbow numbers: \" + str(elbow_count))\n","\n","# set the path to the folder containing the DICOM images\n","dcm_path_abnormal = '/content/drive/My Drive/Deep_X_torch/original_dataset/abnormal/abnormal(.dcm)'\n","output_path_abnormal = '/content/drive/My Drive/Deep_X_torch/original_dataset/abnormal'\n","dcm_path_normal = '/content/drive/My Drive/Deep_X_torch/original_dataset/normal/normal(.dcm)'\n","output_path_normal = '/content/drive/My Drive/Deep_X_torch/original_dataset/normal'\n","\n","# dcm_to_png(dcm_path_abnormal, output_path_abnormal, 'abnormal')\n","# dcm_to_png(dcm_path_normal, output_path_normal, 'normal')\n","\n","dcm_path_test = '/content/drive/My Drive/Deep_X_torch/original_dataset/test/test(.dcm)'\n","output_path_test = '/content/drive/My Drive/Deep_X_torch/original_dataset/test'\n","\n","dcm_to_png(dcm_path_test, output_path_test, 'test')"]},{"cell_type":"markdown","metadata":{"id":"hsQhWruTS-HN"},"source":["#資料前處理"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxsk1T72ib7I"},"outputs":[],"source":["import cv2\n","import os\n","\n","def remove_noise(img, kernel_size=(9, 9)):\n","    \"\"\"去除噪聲\"\"\"\n","    blurred = cv2.GaussianBlur(img, kernel_size, 0)\n","    return blurred\n","\n","def gray_scale(img):\n","    \"\"\"轉換為灰度影像\"\"\"\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    return gray\n","\n","def process_images(input_dir, output_dir):\n","    for filename in os.listdir(input_dir):\n","        if filename.endswith('.jpg'):\n","            input_path = os.path.join(input_dir, filename)\n","            output_path = os.path.join(output_dir, filename)\n","\n","            img = cv2.imread(input_path)\n","            clahe = cv2.createCLAHE(clipLimit=1)\n","            gray_img = gray_scale(img)\n","            clahe_img = clahe.apply(gray_img)\n","            cv2.imwrite(output_path, clahe_img)\n","\n","normal_input_dir = '/content/drive/My Drive/Deep_X_torch/original_dataset/normal/normal(.jpg)'\n","normal_output_dir = '/content/drive/My Drive/Deep_X_torch/processed_dataset/normal'\n","\n","abnormal_input_dir = '/content/drive/My Drive/Deep_X_torch/original_dataset/abnormal/abnormal(.jpg)'\n","abnormal_output_dir = '/content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal'\n","\n","process_images(normal_input_dir, normal_output_dir)\n","process_images(abnormal_input_dir, abnormal_output_dir)"]},{"cell_type":"markdown","metadata":{"id":"ZnUUgJ0iOtxE"},"source":["#區分訓練集(train)和測試集(test)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23331,"status":"ok","timestamp":1697350647422,"user":{"displayName":"陳均葦","userId":"12397795912524578037"},"user_tz":-480},"id":"yPhvl_dQOsUI","outputId":"284c4215-7037-4165-96e2-36bd7eb4b27f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_5.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_6.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_19.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_28.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_18.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_4.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_7.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_13.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_31.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_14.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_26.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_9.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_27.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_20.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_29.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_8.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_23.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_1.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_22.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_11.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_30.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_17.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_13.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_4.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_8.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_2.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_1.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_5.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_11.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_9.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_10.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_15.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_7.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_25.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_2.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_24.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_10.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_15.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_32.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_12.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_16.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_21.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/abnormal/abnormal_3.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_16.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_12.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_6.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_3.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/normal/\n","Copying file /content/drive/My Drive/Deep_X_torch/processed_dataset/normal/normal_14.jpg to /content/drive/My Drive/Deep_X_torch/splitted_dataset/test/normal/\n"]}],"source":["#Split the raw dataset into train set, valid set and test set.\n","import os\n","import random\n","import shutil\n","\n","TRAIN_SET_RATIO = 0.7\n","TEST_SET_RATIO = 0.3\n","\n","class SplitDataset():\n","    def __init__(self, dataset_dir, saved_dataset_dir, train_ratio=TRAIN_SET_RATIO, test_ratio=TEST_SET_RATIO, show_progress=False):\n","        self.dataset_dir = '/content/drive/My Drive/Deep_X_torch/processed_dataset/'\n","        self.saved_dataset_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/'\n","        self.saved_train_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train/'\n","        self.saved_test_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/test/'\n","\n","        self.train_ratio = train_ratio\n","        self.test_radio = test_ratio\n","\n","        self.train_file_path = []\n","        self.test_file_path = []\n","\n","        self.index_label_dict = {}\n","\n","        self.show_progress = show_progress\n","\n","        if not os.path.exists(self.saved_train_dir):\n","            os.mkdir(self.saved_train_dir)\n","        if not os.path.exists(self.saved_test_dir):\n","            os.mkdir(self.saved_test_dir)\n","\n","\n","    def __get_label_names(self):\n","        label_names = []\n","        for item in os.listdir(self.dataset_dir):\n","            item_path = os.path.join(self.dataset_dir, item)\n","            if os.path.isdir(item_path):\n","                label_names.append(item)\n","        return label_names\n","\n","    def __get_all_file_path(self):\n","        all_file_path = []\n","        index = 0\n","        for file_type in self.__get_label_names():\n","            self.index_label_dict[index] = file_type\n","            index += 1\n","            type_file_path = os.path.join(self.dataset_dir, file_type)\n","            file_path = []\n","            for file in os.listdir(type_file_path):\n","                single_file_path = os.path.join(type_file_path, file)\n","                file_path.append(single_file_path)\n","            all_file_path.append(file_path)\n","        return all_file_path\n","\n","    def __copy_files(self, type_path, type_saved_dir):\n","        for item in type_path:\n","            src_path_list = item[1]\n","            dst_path = type_saved_dir + \"%s/\" % (item[0])\n","            if not os.path.exists(dst_path):\n","                os.mkdir(dst_path)\n","            for src_path in src_path_list:\n","                shutil.copy(src_path, dst_path)\n","                if self.show_progress:\n","                    print(\"Copying file \"+src_path+\" to \"+dst_path)\n","\n","    def __split_dataset(self):\n","        all_file_paths = self.__get_all_file_path()\n","        for index in range(len(all_file_paths)):\n","            file_path_list = all_file_paths[index]\n","            file_path_list_length = len(file_path_list)\n","            random.shuffle(file_path_list)\n","\n","            train_num = int(file_path_list_length * self.train_ratio)\n","            test_num = int(file_path_list_length * self.test_radio)\n","            test_num += 1\n","\n","            self.train_file_path.append([self.index_label_dict[index], file_path_list[: train_num]])\n","            self.test_file_path.append([self.index_label_dict[index], file_path_list[train_num:train_num + test_num]])\n","\n","    def start_splitting(self):\n","        self.__split_dataset()\n","        self.__copy_files(type_path=self.train_file_path, type_saved_dir=self.saved_train_dir)\n","        self.__copy_files(type_path=self.test_file_path, type_saved_dir=self.saved_test_dir)\n","\n","\n","if __name__ == '__main__':\n","    split_dataset = SplitDataset(dataset_dir='/content/drive/My Drive/Deep_X_torch/processed_dataset/',\n","                                 saved_dataset_dir='/content/drive/My Drive/Deep_X_torch/splitted_dataset/',\n","                                 show_progress=True)\n","    split_dataset.start_splitting()"]},{"cell_type":"markdown","metadata":{"id":"kgU18ivPXfIq"},"source":["#訓練集資料增強\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4803,"status":"ok","timestamp":1697350652214,"user":{"displayName":"陳均葦","userId":"12397795912524578037"},"user_tz":-480},"id":"jgOJ_cRl9Kio","outputId":"55eb0421-9ddb-4c36-ea94-06a092923592"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting imagecorruptions\n","  Downloading imagecorruptions-1.1.2-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from imagecorruptions) (9.4.0)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from imagecorruptions) (1.23.5)\n","Requirement already satisfied: opencv-python>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from imagecorruptions) (4.8.0.76)\n","Requirement already satisfied: scikit-image>=0.15 in /usr/local/lib/python3.10/dist-packages (from imagecorruptions) (0.19.3)\n","Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from imagecorruptions) (1.11.3)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15->imagecorruptions) (3.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15->imagecorruptions) (2.31.5)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15->imagecorruptions) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15->imagecorruptions) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15->imagecorruptions) (23.2)\n","Installing collected packages: imagecorruptions\n","Successfully installed imagecorruptions-1.1.2\n"]}],"source":["!pip install imagecorruptions"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":747306,"status":"ok","timestamp":1697351399517,"user":{"displayName":"陳均葦","userId":"12397795912524578037"},"user_tz":-480},"id":"IudZMcitXoHB","outputId":"fb831cf6-df82-4a1a-af10-d47a3b19b3ae"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:03<01:02,  3.29s/it]\u001b[A\n"," 10%|█         | 2/20 [00:03<00:26,  1.48s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:09<00:57,  3.39s/it]\u001b[A\n"," 20%|██        | 4/20 [00:13<00:59,  3.74s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:13<00:36,  2.45s/it]\u001b[A\n"," 30%|███       | 6/20 [00:13<00:23,  1.69s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:14<00:15,  1.20s/it]\u001b[A\n"," 40%|████      | 8/20 [00:14<00:11,  1.08it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:15<00:10,  1.07it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:22<00:30,  3.00s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:28<00:33,  3.76s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:28<00:21,  2.67s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:28<00:13,  1.92s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:28<00:08,  1.40s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:29<00:05,  1.07s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:29<00:03,  1.14it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:36<00:07,  2.67s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:39<00:05,  2.67s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:39<00:01,  1.90s/it]\u001b[A\n","100%|██████████| 20/20 [00:39<00:00,  1.98s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:03<01:06,  3.52s/it]\u001b[A\n"," 10%|█         | 2/20 [00:03<00:27,  1.54s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:07<00:43,  2.56s/it]\u001b[A\n"," 20%|██        | 4/20 [00:07<00:26,  1.63s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:07<00:16,  1.13s/it]\u001b[A\n"," 30%|███       | 6/20 [00:12<00:33,  2.36s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:12<00:21,  1.67s/it]\u001b[A\n"," 40%|████      | 8/20 [00:13<00:14,  1.18s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:13<00:10,  1.06it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:13<00:07,  1.42it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:13<00:04,  1.87it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:13<00:03,  2.43it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:16<00:08,  1.19s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:20<00:11,  1.88s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:24<00:13,  2.66s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:27<00:11,  2.81s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:28<00:06,  2.03s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:28<00:02,  1.47s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:31<00:02,  2.08s/it]\u001b[A\n","100%|██████████| 20/20 [00:32<00:00,  1.61s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:04<01:24,  4.44s/it]\u001b[A\n"," 10%|█         | 2/20 [00:08<01:12,  4.00s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:08<00:38,  2.27s/it]\u001b[A\n"," 20%|██        | 4/20 [00:08<00:23,  1.46s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:11<00:30,  2.04s/it]\u001b[A\n"," 30%|███       | 6/20 [00:15<00:35,  2.52s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:15<00:22,  1.74s/it]\u001b[A\n"," 40%|████      | 8/20 [00:15<00:15,  1.33s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:15<00:10,  1.02it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:16<00:07,  1.38it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:20<00:16,  1.82s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:20<00:10,  1.34s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:20<00:06,  1.01it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:20<00:04,  1.35it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:21<00:02,  1.75it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:24<00:05,  1.45s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:28<00:06,  2.09s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:28<00:03,  1.53s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:32<00:02,  2.25s/it]\u001b[A\n","100%|██████████| 20/20 [00:36<00:00,  1.84s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:03,  5.19it/s]\u001b[A\n"," 10%|█         | 2/20 [00:02<00:29,  1.64s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:02<00:15,  1.07it/s]\u001b[A\n"," 20%|██        | 4/20 [00:03<00:11,  1.34it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:03<00:07,  1.91it/s]\u001b[A\n"," 30%|███       | 6/20 [00:06<00:17,  1.26s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:09<00:23,  1.78s/it]\u001b[A\n"," 40%|████      | 8/20 [00:12<00:28,  2.39s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:12<00:18,  1.68s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:15<00:21,  2.11s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:16<00:13,  1.51s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:16<00:08,  1.10s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:16<00:05,  1.25it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:16<00:03,  1.70it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:16<00:02,  2.25it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:16<00:01,  2.88it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:16<00:00,  3.34it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:17<00:00,  4.16it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:17<00:00,  4.72it/s]\u001b[A\n","100%|██████████| 20/20 [00:19<00:00,  1.01it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:02,  7.71it/s]\u001b[A\n"," 10%|█         | 2/20 [00:02<00:26,  1.45s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:02<00:14,  1.18it/s]\u001b[A\n"," 20%|██        | 4/20 [00:02<00:09,  1.70it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:07<00:29,  1.97s/it]\u001b[A\n"," 30%|███       | 6/20 [00:07<00:18,  1.34s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:07<00:12,  1.06it/s]\u001b[A\n"," 40%|████      | 8/20 [00:09<00:16,  1.39s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:09<00:11,  1.00s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:12<00:09,  1.10s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:14<00:11,  1.42s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:14<00:07,  1.08s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:14<00:04,  1.24it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:15<00:03,  1.56it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:17<00:04,  1.22s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:18<00:03,  1.14s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:18<00:01,  1.16it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:22<00:01,  1.51s/it]\u001b[A\n","100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:03,  5.30it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:02,  6.13it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:04<00:31,  1.83s/it]\u001b[A\n"," 20%|██        | 4/20 [00:07<00:39,  2.45s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:14<00:58,  3.91s/it]\u001b[A\n"," 30%|███       | 6/20 [00:14<00:36,  2.63s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:14<00:25,  1.95s/it]\u001b[A\n"," 40%|████      | 8/20 [00:14<00:16,  1.40s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:15<00:11,  1.01s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:18<00:17,  1.79s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:18<00:11,  1.28s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:18<00:07,  1.07it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:19<00:04,  1.45it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:22<00:08,  1.42s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:22<00:05,  1.06s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:22<00:03,  1.28it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:22<00:01,  1.62it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:27<00:03,  1.72s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:27<00:01,  1.30s/it]\u001b[A\n","100%|██████████| 20/20 [00:27<00:00,  1.39s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:03<01:05,  3.45s/it]\u001b[A\n"," 10%|█         | 2/20 [00:03<00:30,  1.72s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:04<00:17,  1.03s/it]\u001b[A\n"," 20%|██        | 4/20 [00:04<00:13,  1.16it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:08<00:27,  1.80s/it]\u001b[A\n"," 30%|███       | 6/20 [00:12<00:35,  2.56s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:12<00:23,  1.79s/it]\u001b[A\n"," 40%|████      | 8/20 [00:12<00:15,  1.29s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:13<00:11,  1.02s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:16<00:18,  1.85s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:20<00:20,  2.33s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:23<00:21,  2.67s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:23<00:13,  1.91s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:28<00:16,  2.72s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:32<00:14,  2.99s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:32<00:08,  2.13s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:32<00:04,  1.53s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:32<00:02,  1.11s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:32<00:00,  1.22it/s]\u001b[A\n","100%|██████████| 20/20 [00:32<00:00,  1.64s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:01<00:34,  1.81s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:02<00:09,  1.84it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:02<00:04,  3.17it/s]\u001b[A\n"," 30%|███       | 6/20 [00:02<00:03,  3.73it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:04<00:09,  1.42it/s]\u001b[A\n"," 40%|████      | 8/20 [00:06<00:13,  1.14s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:09<00:17,  1.61s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:09<00:11,  1.17s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:09<00:05,  1.45it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:11<00:06,  1.10it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:12<00:06,  1.14s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:14<00:06,  1.35s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:16<00:05,  1.49s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:18<00:04,  1.58s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:20<00:03,  1.78s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:21<00:01,  1.34s/it]\u001b[A\n","100%|██████████| 20/20 [00:21<00:00,  1.06s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:06,  3.00it/s]\u001b[A\n"," 10%|█         | 2/20 [00:03<00:35,  1.99s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:03<00:19,  1.15s/it]\u001b[A\n"," 20%|██        | 4/20 [00:03<00:12,  1.33it/s]\u001b[A\n"," 30%|███       | 6/20 [00:03<00:05,  2.45it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:06<00:12,  1.07it/s]\u001b[A\n"," 40%|████      | 8/20 [00:09<00:17,  1.50s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:09<00:12,  1.10s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:09<00:08,  1.24it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:12<00:12,  1.35s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:12<00:07,  1.01it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:12<00:05,  1.34it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:16<00:09,  1.61s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:16<00:06,  1.20s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:16<00:03,  1.14it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:16<00:01,  1.51it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:19<00:02,  1.27s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:19<00:00,  1.07it/s]\u001b[A\n","100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:02,  8.33it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:02,  6.91it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:00<00:02,  8.05it/s]\u001b[A\n"," 20%|██        | 4/20 [00:00<00:02,  7.55it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:00<00:01,  8.14it/s]\u001b[A\n"," 30%|███       | 6/20 [00:02<00:10,  1.29it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:02<00:07,  1.71it/s]\u001b[A\n"," 40%|████      | 8/20 [00:02<00:05,  2.28it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:03<00:03,  2.81it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:03<00:02,  3.46it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:03<00:02,  4.18it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:03<00:01,  4.72it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:06<00:06,  1.04it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:09<00:09,  1.57s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:11<00:09,  1.82s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:11<00:03,  1.02s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:11<00:01,  1.26it/s]\u001b[A\n","100%|██████████| 20/20 [00:12<00:00,  1.65it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:03<01:05,  3.42s/it]\u001b[A\n"," 10%|█         | 2/20 [00:03<00:27,  1.54s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:03<00:15,  1.11it/s]\u001b[A\n"," 20%|██        | 4/20 [00:03<00:09,  1.65it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:04<00:06,  2.27it/s]\u001b[A\n"," 30%|███       | 6/20 [00:04<00:04,  2.98it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:08<00:20,  1.56s/it]\u001b[A\n"," 40%|████      | 8/20 [00:08<00:14,  1.19s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:08<00:09,  1.13it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:09<00:07,  1.42it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:09<00:05,  1.58it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:10<00:04,  1.80it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:10<00:03,  2.14it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:10<00:02,  2.59it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:14<00:07,  1.41s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:14<00:04,  1.03s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:14<00:02,  1.29it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:18<00:03,  1.58s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:18<00:01,  1.20s/it]\u001b[A\n","100%|██████████| 20/20 [00:18<00:00,  1.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["增強前圖片數量：11\n","增強後圖片數量：220\n","數據增強完成\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:02,  8.69it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:02,  7.92it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:00<00:02,  6.78it/s]\u001b[A\n"," 20%|██        | 4/20 [00:00<00:02,  5.52it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:00<00:02,  6.18it/s]\u001b[A\n"," 30%|███       | 6/20 [00:05<00:22,  1.61s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:08<00:28,  2.23s/it]\u001b[A\n"," 40%|████      | 8/20 [00:12<00:31,  2.59s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:15<00:31,  2.87s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:15<00:20,  2.04s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:16<00:14,  1.62s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:20<00:18,  2.30s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:20<00:11,  1.66s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:23<00:12,  2.06s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:26<00:12,  2.48s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:27<00:07,  1.79s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:27<00:03,  1.30s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:27<00:02,  1.01s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:27<00:00,  1.35it/s]\u001b[A\n","100%|██████████| 20/20 [00:31<00:00,  1.58s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:02,  6.44it/s]\u001b[A\n"," 10%|█         | 2/20 [00:02<00:28,  1.57s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:02<00:15,  1.11it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:02<00:06,  2.28it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:03<00:03,  3.51it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:03<00:02,  4.55it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:03<00:01,  5.79it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:03<00:01,  6.31it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:03<00:00,  7.02it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:05<00:01,  2.26it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:06<00:01,  2.64it/s]\u001b[A\n","100%|██████████| 20/20 [00:08<00:00,  2.43it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 2/20 [00:01<00:12,  1.42it/s]\u001b[A\n"," 20%|██        | 4/20 [00:02<00:11,  1.34it/s]\u001b[A\n"," 30%|███       | 6/20 [00:04<00:10,  1.34it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:06<00:13,  1.01s/it]\u001b[A\n"," 40%|████      | 8/20 [00:06<00:09,  1.29it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:06<00:06,  1.64it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:06<00:04,  2.10it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:08<00:07,  1.16it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:08<00:03,  1.97it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:08<00:02,  2.44it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:10<00:02,  1.93it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:11<00:01,  1.72it/s]\u001b[A\n","100%|██████████| 20/20 [00:11<00:00,  1.71it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:02,  9.29it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:01,  9.47it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:01<00:12,  1.38it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:01<00:05,  2.71it/s]\u001b[A\n"," 30%|███       | 6/20 [00:01<00:04,  3.39it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:02<00:03,  4.06it/s]\u001b[A\n"," 40%|████      | 8/20 [00:02<00:03,  3.73it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:04<00:07,  1.49it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:05<00:08,  1.11it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:05<00:04,  1.89it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:07<00:04,  1.47it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:09<00:04,  1.01it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:09<00:01,  1.52it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:10<00:01,  1.78it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:10<00:00,  2.20it/s]\u001b[A\n","100%|██████████| 20/20 [00:10<00:00,  1.88it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:03<01:05,  3.44s/it]\u001b[A\n"," 10%|█         | 2/20 [00:03<00:27,  1.51s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:03<00:16,  1.05it/s]\u001b[A\n"," 20%|██        | 4/20 [00:04<00:10,  1.50it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:04<00:07,  1.99it/s]\u001b[A\n"," 30%|███       | 6/20 [00:07<00:20,  1.46s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:07<00:13,  1.03s/it]\u001b[A\n"," 40%|████      | 8/20 [00:12<00:25,  2.12s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:12<00:16,  1.52s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:12<00:11,  1.16s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:12<00:07,  1.16it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:13<00:05,  1.47it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:13<00:03,  1.90it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:13<00:02,  2.21it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:17<00:07,  1.51s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:21<00:08,  2.09s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:21<00:04,  1.55s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:21<00:02,  1.16s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:21<00:00,  1.15it/s]\u001b[A\n","100%|██████████| 20/20 [00:25<00:00,  1.28s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:03,  6.29it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:03,  5.68it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:00<00:03,  4.35it/s]\u001b[A\n"," 20%|██        | 4/20 [00:00<00:03,  5.01it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:01<00:03,  4.57it/s]\u001b[A\n"," 30%|███       | 6/20 [00:04<00:16,  1.18s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:04<00:11,  1.17it/s]\u001b[A\n"," 40%|████      | 8/20 [00:06<00:15,  1.33s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:06<00:11,  1.02s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:07<00:07,  1.33it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:07<00:05,  1.72it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:07<00:03,  2.29it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:07<00:02,  2.74it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:07<00:01,  4.08it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:08<00:00,  5.40it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:10<00:01,  1.53it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:12<00:01,  1.05s/it]\u001b[A\n","100%|██████████| 20/20 [00:12<00:00,  1.56it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:02,  8.26it/s]\u001b[A\n"," 10%|█         | 2/20 [00:04<00:48,  2.68s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:07<00:51,  3.01s/it]\u001b[A\n"," 20%|██        | 4/20 [00:08<00:29,  1.87s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:11<00:35,  2.40s/it]\u001b[A\n"," 30%|███       | 6/20 [00:11<00:22,  1.63s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:11<00:14,  1.15s/it]\u001b[A\n"," 40%|████      | 8/20 [00:15<00:23,  1.92s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:19<00:29,  2.70s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:19<00:19,  1.93s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:23<00:21,  2.38s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:26<00:21,  2.69s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:30<00:21,  3.03s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:30<00:13,  2.19s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:35<00:14,  2.81s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:35<00:08,  2.01s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:35<00:04,  1.44s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:35<00:02,  1.05s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:35<00:00,  1.29it/s]\u001b[A\n","100%|██████████| 20/20 [00:39<00:00,  1.95s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:03<01:06,  3.52s/it]\u001b[A\n"," 10%|█         | 2/20 [00:03<00:27,  1.55s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:03<00:15,  1.10it/s]\u001b[A\n"," 20%|██        | 4/20 [00:04<00:10,  1.59it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:04<00:06,  2.16it/s]\u001b[A\n"," 30%|███       | 6/20 [00:08<00:26,  1.91s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:09<00:17,  1.34s/it]\u001b[A\n"," 40%|████      | 8/20 [00:09<00:11,  1.04it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:09<00:07,  1.39it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:09<00:05,  1.84it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:13<00:12,  1.43s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:13<00:08,  1.04s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:13<00:05,  1.30it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:16<00:09,  1.58s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:16<00:05,  1.16s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:21<00:08,  2.04s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:24<00:07,  2.57s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:28<00:05,  2.93s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:31<00:03,  3.01s/it]\u001b[A\n","100%|██████████| 20/20 [00:31<00:00,  1.60s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:04<01:19,  4.21s/it]\u001b[A\n"," 10%|█         | 2/20 [00:04<00:33,  1.83s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:07<00:39,  2.35s/it]\u001b[A\n"," 20%|██        | 4/20 [00:07<00:24,  1.50s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:10<00:30,  2.01s/it]\u001b[A\n"," 30%|███       | 6/20 [00:13<00:32,  2.31s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:13<00:20,  1.59s/it]\u001b[A\n"," 40%|████      | 8/20 [00:17<00:27,  2.30s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:17<00:17,  1.63s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:20<00:20,  2.08s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:21<00:14,  1.61s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:21<00:09,  1.15s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:21<00:05,  1.18it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:21<00:03,  1.60it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:21<00:02,  2.06it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:21<00:01,  2.66it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:24<00:03,  1.03s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:24<00:01,  1.32it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:24<00:00,  1.68it/s]\u001b[A\n","100%|██████████| 20/20 [00:24<00:00,  1.24s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:02<00:40,  2.11s/it]\u001b[A\n"," 10%|█         | 2/20 [00:02<00:16,  1.07it/s]\u001b[A\n"," 20%|██        | 4/20 [00:04<00:18,  1.17s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:08<00:26,  1.79s/it]\u001b[A\n"," 30%|███       | 6/20 [00:10<00:26,  1.89s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:10<00:17,  1.35s/it]\u001b[A\n"," 40%|████      | 8/20 [00:12<00:19,  1.66s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:12<00:13,  1.21s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:12<00:08,  1.12it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:13<00:06,  1.49it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:13<00:04,  1.94it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:13<00:03,  2.25it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:13<00:02,  2.92it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:15<00:02,  1.57it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:17<00:03,  1.03s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:18<00:01,  1.24it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:18<00:00,  1.55it/s]\u001b[A\n","100%|██████████| 20/20 [00:18<00:00,  1.09it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:12,  1.51it/s]\u001b[A\n"," 10%|█         | 2/20 [00:04<00:41,  2.30s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:06<00:41,  2.47s/it]\u001b[A\n"," 20%|██        | 4/20 [00:06<00:24,  1.55s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:07<00:15,  1.04s/it]\u001b[A\n"," 30%|███       | 6/20 [00:07<00:10,  1.38it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:09<00:17,  1.37s/it]\u001b[A\n"," 40%|████      | 8/20 [00:09<00:11,  1.03it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:10<00:07,  1.42it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:12<00:13,  1.31s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:12<00:08,  1.05it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:13<00:07,  1.14it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:17<00:12,  1.72s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:17<00:07,  1.27s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:17<00:04,  1.08it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:17<00:02,  1.46it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:20<00:03,  1.28s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:20<00:01,  1.08it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:20<00:00,  1.47it/s]\u001b[A\n","100%|██████████| 20/20 [00:20<00:00,  1.04s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:03<01:11,  3.78s/it]\u001b[A\n"," 10%|█         | 2/20 [00:03<00:29,  1.66s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:04<00:16,  1.03it/s]\u001b[A\n"," 20%|██        | 4/20 [00:07<00:33,  2.10s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:08<00:21,  1.45s/it]\u001b[A\n"," 30%|███       | 6/20 [00:08<00:14,  1.06s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:08<00:10,  1.29it/s]\u001b[A\n"," 40%|████      | 8/20 [00:08<00:07,  1.65it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:09<00:05,  2.01it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:13<00:15,  1.54s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:13<00:10,  1.13s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:16<00:14,  1.82s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:16<00:09,  1.34s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:17<00:06,  1.00s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:17<00:03,  1.30it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:17<00:02,  1.68it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:17<00:01,  2.13it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:18<00:00,  2.44it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:18<00:00,  2.99it/s]\u001b[A\n","100%|██████████| 20/20 [00:18<00:00,  1.09it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:03<01:13,  3.87s/it]\u001b[A\n"," 10%|█         | 2/20 [00:04<00:31,  1.75s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:04<00:18,  1.06s/it]\u001b[A\n"," 20%|██        | 4/20 [00:08<00:37,  2.32s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:12<00:40,  2.72s/it]\u001b[A\n"," 30%|███       | 6/20 [00:12<00:25,  1.84s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:12<00:16,  1.28s/it]\u001b[A\n"," 40%|████      | 8/20 [00:12<00:11,  1.08it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:15<00:18,  1.72s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:16<00:12,  1.27s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:20<00:20,  2.25s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:20<00:12,  1.61s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:21<00:08,  1.19s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:21<00:05,  1.15it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:24<00:08,  1.66s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:24<00:04,  1.22s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:28<00:05,  1.88s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:28<00:02,  1.39s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:28<00:01,  1.03s/it]\u001b[A\n","100%|██████████| 20/20 [00:28<00:00,  1.45s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:01,  9.61it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:00<00:01, 11.37it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:01<00:06,  2.48it/s]\u001b[A\n"," 30%|███       | 6/20 [00:01<00:04,  2.99it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:01<00:03,  3.70it/s]\u001b[A\n"," 40%|████      | 8/20 [00:02<00:02,  4.41it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:04<00:08,  1.35it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:04<00:05,  1.76it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:04<00:04,  1.93it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:04<00:03,  2.38it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:04<00:02,  2.86it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:05<00:01,  3.54it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:06<00:03,  1.34it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:07<00:02,  1.80it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:07<00:01,  2.37it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:07<00:00,  3.02it/s]\u001b[A\n","100%|██████████| 20/20 [00:08<00:00,  2.28it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:02,  8.78it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:02,  7.83it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:03<00:28,  1.69s/it]\u001b[A\n"," 20%|██        | 4/20 [00:04<00:17,  1.11s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:04<00:12,  1.23it/s]\u001b[A\n"," 30%|███       | 6/20 [00:04<00:08,  1.73it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:04<00:05,  2.26it/s]\u001b[A\n"," 40%|████      | 8/20 [00:04<00:04,  2.87it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:08<00:16,  1.48s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:09<00:12,  1.27s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:09<00:08,  1.03it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:10<00:06,  1.29it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:10<00:04,  1.50it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:10<00:03,  1.77it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:11<00:02,  2.12it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:11<00:01,  2.61it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:11<00:01,  2.88it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:11<00:00,  3.50it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:11<00:00,  4.08it/s]\u001b[A\n","100%|██████████| 20/20 [00:12<00:00,  1.65it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:04,  3.83it/s]\u001b[A\n"," 10%|█         | 2/20 [00:03<00:35,  2.00s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:03<00:19,  1.15s/it]\u001b[A\n"," 20%|██        | 4/20 [00:03<00:12,  1.27it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:03<00:08,  1.81it/s]\u001b[A\n"," 30%|███       | 6/20 [00:04<00:05,  2.45it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:07<00:17,  1.36s/it]\u001b[A\n"," 40%|████      | 8/20 [00:11<00:25,  2.12s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:11<00:16,  1.53s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:15<00:22,  2.30s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:15<00:14,  1.64s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:15<00:09,  1.20s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:15<00:06,  1.14it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:16<00:04,  1.46it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:16<00:02,  1.93it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:19<00:05,  1.37s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:19<00:03,  1.03s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:23<00:03,  1.70s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:23<00:01,  1.33s/it]\u001b[A\n","100%|██████████| 20/20 [00:28<00:00,  1.40s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:03,  5.21it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:03,  5.25it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:04<00:33,  1.97s/it]\u001b[A\n"," 20%|██        | 4/20 [00:04<00:20,  1.25s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:08<00:30,  2.06s/it]\u001b[A\n"," 30%|███       | 6/20 [00:08<00:20,  1.45s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:08<00:13,  1.02s/it]\u001b[A\n"," 40%|████      | 8/20 [00:08<00:09,  1.27it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:08<00:06,  1.68it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:09<00:04,  2.20it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:09<00:03,  2.57it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:09<00:02,  3.13it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:14<00:11,  1.60s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:14<00:06,  1.17s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:14<00:04,  1.15it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:17<00:06,  1.69s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:21<00:06,  2.25s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:21<00:03,  1.63s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:21<00:01,  1.19s/it]\u001b[A\n","100%|██████████| 20/20 [00:25<00:00,  1.29s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:03,  5.22it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:03,  5.22it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:00<00:05,  3.28it/s]\u001b[A\n"," 20%|██        | 4/20 [00:04<00:27,  1.71s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:04<00:17,  1.14s/it]\u001b[A\n"," 30%|███       | 6/20 [00:08<00:27,  1.95s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:08<00:17,  1.38s/it]\u001b[A\n"," 40%|████      | 8/20 [00:08<00:11,  1.01it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:12<00:19,  1.79s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:12<00:13,  1.36s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:17<00:20,  2.29s/it]\u001b[A\n"," 60%|██████    | 12/20 [00:20<00:21,  2.65s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:23<00:20,  2.89s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:27<00:19,  3.22s/it]\u001b[A\n"," 75%|███████▌  | 15/20 [00:32<00:17,  3.51s/it]\u001b[A\n"," 80%|████████  | 16/20 [00:32<00:10,  2.53s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:35<00:08,  2.81s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:35<00:04,  2.01s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:36<00:01,  1.44s/it]\u001b[A\n","100%|██████████| 20/20 [00:36<00:00,  1.82s/it]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:02,  7.11it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:03,  4.71it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:00<00:03,  4.48it/s]\u001b[A\n"," 20%|██        | 4/20 [00:00<00:03,  4.29it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:01<00:03,  4.82it/s]\u001b[A\n"," 30%|███       | 6/20 [00:01<00:02,  5.04it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:01<00:02,  5.29it/s]\u001b[A\n"," 40%|████      | 8/20 [00:01<00:02,  5.51it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:02<00:02,  3.72it/s]\u001b[A\n"," 50%|█████     | 10/20 [00:02<00:02,  4.29it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:02<00:01,  4.64it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:02<00:01,  4.80it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:02<00:01,  5.31it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:02<00:01,  5.04it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:03<00:00,  5.49it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:03<00:00,  5.02it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:03<00:00,  4.55it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:07<00:02,  1.48s/it]\u001b[A\n"," 95%|█████████▌| 19/20 [00:11<00:02,  2.09s/it]\u001b[A\n","100%|██████████| 20/20 [00:14<00:00,  1.38it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:02<00:40,  2.12s/it]\u001b[A\n"," 10%|█         | 2/20 [00:04<00:41,  2.28s/it]\u001b[A\n"," 15%|█▌        | 3/20 [00:07<00:41,  2.41s/it]\u001b[A\n"," 20%|██        | 4/20 [00:07<00:24,  1.52s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:09<00:26,  1.76s/it]\u001b[A\n"," 30%|███       | 6/20 [00:09<00:16,  1.20s/it]\u001b[A\n"," 40%|████      | 8/20 [00:09<00:07,  1.53it/s]\u001b[A\n"," 45%|████▌     | 9/20 [00:11<00:11,  1.01s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:11<00:07,  1.31it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:14<00:07,  1.07it/s]\u001b[A\n"," 65%|██████▌   | 13/20 [00:16<00:08,  1.21s/it]\u001b[A\n"," 70%|███████   | 14/20 [00:16<00:05,  1.07it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:16<00:02,  1.75it/s]\u001b[A\n"," 85%|████████▌ | 17/20 [00:16<00:01,  2.12it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:16<00:00,  3.13it/s]\u001b[A\n","100%|██████████| 20/20 [00:16<00:00,  1.18it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:01, 13.33it/s]\u001b[A\n"," 20%|██        | 4/20 [00:00<00:02,  7.20it/s]\u001b[A\n"," 25%|██▌       | 5/20 [00:02<00:09,  1.59it/s]\u001b[A\n"," 30%|███       | 6/20 [00:04<00:14,  1.00s/it]\u001b[A\n"," 35%|███▌      | 7/20 [00:05<00:15,  1.17s/it]\u001b[A\n"," 40%|████      | 8/20 [00:07<00:14,  1.24s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:08<00:10,  1.00s/it]\u001b[A\n"," 55%|█████▌    | 11/20 [00:08<00:07,  1.23it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:10<00:07,  1.04it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:10<00:03,  1.59it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:12<00:02,  1.50it/s]\u001b[A\n"," 90%|█████████ | 18/20 [00:13<00:01,  1.45it/s]\u001b[A\n","100%|██████████| 20/20 [00:13<00:00,  1.46it/s]\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n","  5%|▌         | 1/20 [00:00<00:02,  7.74it/s]\u001b[A\n"," 10%|█         | 2/20 [00:00<00:02,  6.53it/s]\u001b[A\n"," 15%|█▌        | 3/20 [00:00<00:02,  6.02it/s]\u001b[A\n"," 20%|██        | 4/20 [00:04<00:26,  1.64s/it]\u001b[A\n"," 25%|██▌       | 5/20 [00:04<00:17,  1.16s/it]\u001b[A\n"," 30%|███       | 6/20 [00:04<00:11,  1.22it/s]\u001b[A\n"," 35%|███▌      | 7/20 [00:05<00:08,  1.55it/s]\u001b[A\n"," 40%|████      | 8/20 [00:08<00:16,  1.41s/it]\u001b[A\n"," 45%|████▌     | 9/20 [00:08<00:11,  1.04s/it]\u001b[A\n"," 50%|█████     | 10/20 [00:08<00:07,  1.33it/s]\u001b[A\n"," 55%|█████▌    | 11/20 [00:08<00:05,  1.52it/s]\u001b[A\n"," 60%|██████    | 12/20 [00:11<00:10,  1.36s/it]\u001b[A\n"," 65%|██████▌   | 13/20 [00:12<00:06,  1.00it/s]\u001b[A\n"," 70%|███████   | 14/20 [00:12<00:04,  1.36it/s]\u001b[A\n"," 75%|███████▌  | 15/20 [00:12<00:02,  1.78it/s]\u001b[A\n"," 80%|████████  | 16/20 [00:15<00:05,  1.39s/it]\u001b[A\n"," 85%|████████▌ | 17/20 [00:15<00:03,  1.03s/it]\u001b[A\n"," 90%|█████████ | 18/20 [00:16<00:01,  1.21it/s]\u001b[A\n"," 95%|█████████▌| 19/20 [00:20<00:01,  1.74s/it]\u001b[A\n","100%|██████████| 20/20 [00:20<00:00,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["增強前圖片數量：22\n","增強後圖片數量：440\n","數據增強完成\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import glob\n","import cv2\n","import imgaug.augmenters as iaa\n","import os\n","from tqdm import trange\n","\n","def data_augmentation(input_path, output_path, times):\n","    # Define a set of image augmentation operations using imgaug\n","    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n","    seq = iaa.Sequential([\n","        iaa.SomeOf((0, 5), [\n","            # iaa.Fliplr(0),  # 有 0% 的概率水平翻轉\n","            # iaa.Flipud(0),  # 有 0% 的概率垂直翻轉\n","            iaa.Affine(rotate=(-10, 10)),  # 隨機旋轉圖像 0 到 360 度\n","            iaa.OneOf([\n","                iaa.GaussianBlur((0, 3.0)),  # 高斯模糊，模糊程度在 0 到 3.0 之間\n","                iaa.AverageBlur(k=(2, 7)),   # 均值模糊，核的大小在 2 到 7 之間\n","                iaa.MedianBlur(k=(3, 11)),   # 中值模糊，核的大小在 3 到 11 之間\n","            ]),\n","            iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),  # 銳化，參數可調\n","            iaa.Emboss(alpha=(0, 1.0), strength=(0, 1.5)),  # 浮雕效果，參數可調\n","            iaa.Add((-10, 10), per_channel=0.5),  # 添加亮度，每通道亮度值在 -10 到 10 之間\n","            iaa.Multiply((0.5, 1.5)),  # 乘以亮度因子，值在 0.5 到 1.5 之間\n","            iaa.contrast.LinearContrast((0.7, 1.2)),  # 線性對比度，參數可調\n","            iaa.imgcorruptlike.Saturate(severity=3),  # 飽和度增強，程度為 3\n","        ], random_order=True)  # 隨機應用上述操作，順序隨機\n","    ], random_order=True)\n","\n","    # Create the output directory if it doesn't exist\n","    if not os.path.exists(output_path):\n","        os.makedirs(output_path)\n","\n","    # Process each file in the input_path directory\n","    # Process each .jpg file in the input_path directory\n","    file_count = 0\n","    for jpg_file in glob.glob(os.path.join(input_path, '*.jpg')):\n","        img = cv2.imread(jpg_file)\n","        img_list = [img]  # Create a list with a single image\n","\n","        for count in trange(times):\n","            images_aug = seq.augment_images(img_list)\n","            for index, augmented_image in enumerate(images_aug):\n","                filename = os.path.splitext(os.path.basename(jpg_file))[0]  # Extract the filename without extension\n","                output = os.path.join(output_path, f\"{filename}_aug{count + 1}.jpg\")\n","                cv2.imwrite(output, augmented_image)\n","        file_count += 1\n","\n","\n","    # Calculate and print statistics\n","    print(\"增強前圖片數量：\" + str(file_count))\n","    print(\"增強後圖片數量：\" + str(file_count * times))\n","    print(\"數據增強完成\")\n","\n","# Example usage:\n","normal_input_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal'\n","normal_output_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train_argumentation/normal'\n","abnormal_input_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal'\n","abnormal_output_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train_argumentation/abnormal'\n","\n","data_augmentation(normal_input_dir, normal_output_dir, 20)\n","data_augmentation(abnormal_input_dir, abnormal_output_dir, 20)\n","\n","# test_dir = '/content/drive/My Drive/Deep_X_torch/original_dataset/test/test(.jpg)'\n","\n","# data_augmentation(test_dir, test_dir, 20)\n"]},{"cell_type":"markdown","metadata":{"id":"UGOZzdmVR02k"},"source":["#根據使用labelImg標記的label切割JPG檔案"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84841,"status":"ok","timestamp":1697351484351,"user":{"displayName":"陳均葦","userId":"12397795912524578037"},"user_tz":-480},"id":"zFkTIcTqujBh","outputId":"57a96029-f3cc-4085-f8f7-7361dcc8756c"},"outputs":[{"output_type":"stream","name":"stdout","text":["normal_13.txt\n","normal_4.txt\n","normal_8.txt\n","normal_2.txt\n","normal_1.txt\n","normal_5.txt\n","normal_11.txt\n","normal_9.txt\n","normal_10.txt\n","normal_15.txt\n","normal_7.txt\n","abnormal_5.txt\n","abnormal_6.txt\n","abnormal_19.txt\n","abnormal_28.txt\n","abnormal_18.txt\n","abnormal_4.txt\n","abnormal_7.txt\n","abnormal_13.txt\n","abnormal_31.txt\n","abnormal_14.txt\n","abnormal_26.txt\n","abnormal_9.txt\n","abnormal_27.txt\n","abnormal_20.txt\n","abnormal_29.txt\n","abnormal_8.txt\n","abnormal_23.txt\n","abnormal_1.txt\n","abnormal_22.txt\n","abnormal_11.txt\n","abnormal_30.txt\n","abnormal_17.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_13.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_4.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_8.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_2.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_1.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_5.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_11.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_9.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_10.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_15.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","normal_7.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_5.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_6.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_19.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_28.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_18.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_4.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_7.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_13.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_31.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_14.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_26.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_9.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_27.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_20.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_29.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_8.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_23.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_1.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_22.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_11.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_30.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","abnormal_17.txt\n","normal_16.txt\n","normal_12.txt\n","normal_6.txt\n","normal_3.txt\n","normal_14.txt\n","abnormal_25.txt\n","abnormal_2.txt\n","abnormal_24.txt\n","abnormal_10.txt\n","abnormal_15.txt\n","abnormal_32.txt\n","abnormal_12.txt\n","abnormal_16.txt\n","abnormal_21.txt\n","abnormal_3.txt\n"]}],"source":["import cv2\n","import os\n","\n","def crop_images(img_folder, label_folder, save_folder, crop_size=(224, 224)):\n","    # create new folder to save the cropped images\n","    os.makedirs(save_folder, exist_ok=True)\n","\n","    # loop through each image file in the folder\n","    for img_file in os.listdir(img_folder):\n","        # check if the file is an image file\n","        if not img_file.endswith('.jpg'):\n","            continue\n","\n","        # read the corresponding text file\n","        txt_file = img_file.split(\".\")[0]\n","        txt_file = txt_file.split(\"_\")[0] + \"_\" + txt_file.split(\"_\")[1] + '.txt'\n","        txt_path = os.path.join(label_folder, txt_file)\n","        print(txt_file)\n","        if not os.path.exists(txt_path):\n","            continue\n","\n","        # read the image\n","        img_path = os.path.join(img_folder, img_file)\n","        img = cv2.imread(img_path)\n","\n","        # read the bounding box and class label from the text file\n","        with open(txt_path, 'r') as f:\n","            line = f.readline()\n","            class_id, x_center, y_center, width, height = [float(x) for x in line.split()]\n","\n","        # Convert coordinates to the top-left and bottom-right corners of the image\n","        x_min = int((x_center - width / 2) * img.shape[1])\n","        y_min = int((y_center - height / 2) * img.shape[0])\n","        x_max = int((x_center + width / 2) * img.shape[1])\n","        y_max = int((y_center + height / 2) * img.shape[0])\n","\n","        # Crop the image and save it to the save folder\n","        cropped_img = img[y_min:y_max, x_min:x_max]\n","        cropped_img = cv2.resize(cropped_img, crop_size)\n","        save_path = os.path.join(save_folder, img_file)\n","        cv2.imwrite(save_path, cropped_img)\n","\n","normal_label_folder = '/content/drive/My Drive/Deep_X_torch/original_dataset/normal/normal_label'\n","abnormal_label_folder = '/content/drive/My Drive/Deep_X_torch/original_dataset/abnormal/abnormal_label'\n","\n","train_normal_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal'\n","train_abnormal_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal'\n","train_argumentation_normal_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train_argumentation/normal'\n","train_argumentation_abnormal_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train_argumentation/abnormal'\n","test_normal_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/test/normal'\n","test_abnormal_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal'\n","\n","crop_images(train_normal_dir, normal_label_folder, train_normal_dir)\n","crop_images(train_abnormal_dir, abnormal_label_folder, train_abnormal_dir)\n","crop_images(train_argumentation_normal_dir, normal_label_folder, train_argumentation_normal_dir)\n","crop_images(train_argumentation_abnormal_dir, abnormal_label_folder, train_argumentation_abnormal_dir)\n","crop_images(test_normal_dir, normal_label_folder, test_normal_dir)\n","crop_images(test_abnormal_dir, abnormal_label_folder, test_abnormal_dir)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Ej0dyhkN9FIj","executionInfo":{"status":"ok","timestamp":1697351484352,"user_tz":-480,"elapsed":4,"user":{"displayName":"陳均葦","userId":"12397795912524578037"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"2Z0QXaeMnBIu"},"source":["#將圖像轉換為張量"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"QbIXFzMJPVZy","executionInfo":{"status":"ok","timestamp":1697351492651,"user_tz":-480,"elapsed":8302,"user":{"displayName":"陳均葦","userId":"12397795912524578037"}}},"outputs":[],"source":["import os\n","from PIL import Image\n","import torch\n","from torchvision import transforms\n","\n","def transform(image_path,tensor_path):\n","    # 設置轉換方式，將圖像轉換為張量\n","    transform = transforms.Compose([\n","        transforms.ToTensor()\n","    ])\n","\n","    # 遍歷資料夾中的所有檔案\n","    for filename in os.listdir(image_path):\n","        # 讀取圖像\n","        img_path = os.path.join(image_path, filename)\n","        img = Image.open(img_path)\n","\n","        file_name,extension = os.path.splitext(filename)\n","\n","        # 將圖像轉換為張量\n","        tensor_img = transform(img)\n","\n","        # 將張量保存為.pt檔案\n","        tensors_path = os.path.join(tensor_path, file_name + \".pt\")\n","        #print(tensors_path)\n","        torch.save(tensor_img,tensors_path)\n","\n","train_normal_splitted_path = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train_argumentation/normal'\n","train_abnormal_splitted_path = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train_argumentation/abnormal'\n","train_normal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/train/normal'\n","train_abnormal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/train/abnormal'\n","test_normal_splitted_path = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/test/normal'\n","test_abnormal_splitted_path = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/test/abnormal'\n","test_normal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/test/normal'\n","test_abnormal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/test/abnormal'\n","\n","transform(train_normal_splitted_path,train_normal_tensor_path)\n","transform(train_abnormal_splitted_path,train_abnormal_tensor_path)\n","transform(test_normal_splitted_path,test_normal_tensor_path)\n","transform(test_abnormal_splitted_path,test_abnormal_tensor_path)"]},{"cell_type":"markdown","metadata":{"id":"mtkv4P6wKNkv"},"source":["#訓練及驗證模型(5-Fold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zVqVkuZTZmb-","colab":{"base_uri":"https://localhost:8080/","height":500},"executionInfo":{"status":"error","timestamp":1697294641429,"user_tz":-480,"elapsed":20254,"user":{"displayName":"陳均葦","userId":"12397795912524578037"}},"outputId":"a3d86dff-3d57-4358-aa9a-dd38f99070f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["train dataset's size : 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n","100%|██████████| 230M/230M [00:00<00:00, 250MB/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-baa403f701e7>\u001b[0m in \u001b[0;36m<cell line: 451>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0mresult_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/Deep_X_torch/result'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_data_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mabnormal_data_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_normal_tensor_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_abnormal_tensor_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-baa403f701e7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(normal_data_dir, abnormal_data_dir, train_normal_tensor_path, train_abnormal_tensor_path, result_path, num_fold)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;31m#將模型移動到GPU上進行運算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Device used : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn as nn\n","import os\n","import numpy as np\n","import torch.optim as optim\n","import torchvision.models as models\n","import matplotlib.pyplot as plt\n","import csv\n","import random\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import ConcatDataset\n","from sklearn import datasets\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime\n","\n","class MyDataset(Dataset):\n","    def __init__(self, data_path):\n","        self.data_path = data_path\n","        self.class_to_idx = {'abnormal': 1, 'normal': 0}  # 定義類別名稱到類別索引的映射\n","        self.data = []\n","        self.filenames = []  # store filenames\n","        for filename in os.listdir(data_path):\n","            if filename.endswith('.pt'):\n","                tensor = torch.load(os.path.join(data_path, filename))\n","                if filename.split('_')[0] == 'normal':\n","                    label_idx = 0\n","                else:\n","                    label_idx = 1\n","                self.data.append((tensor, label_idx, filename))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        tensor, labels, filename = self.data[index]\n","        return tensor, labels, filename\n","\n","class CombinedDataset(ConcatDataset):\n","    def __init__(self, dataset1, dataset2):\n","        super().__init__([dataset1, dataset2])\n","\n","    def __getitem__(self, index):\n","        return super().__getitem__(index)\n","\n","    def __len__(self):\n","        return super().__len__()\n","\n","\n","# 建立資料夾顯示訓練結果\n","def mkdir_outcome(result_path):\n","    file_names = os.listdir(result_path)\n","    num_max = 0\n","    for file_name in file_names:\n","        if file_name.startswith(\"result_\"):\n","            num_str = file_name.split(\"_\")[1]\n","            num = int(num_str)\n","            if(num > num_max):\n","                num_max = num\n","    # make folder for train result\n","    result_path = os.path.join(result_path,\"result_{}\".format(num_max + 1))\n","    result_path_train = os.path.join(result_path,\"train_{}\".format(num_max + 1))\n","    os.makedirs(result_path,exist_ok=True)\n","    os.makedirs(result_path_train,exist_ok=True)\n","    return result_path_train\n","\n","\n","# 模型評估指標\n","def validation_index(conf_matrix):\n","    # Confusion Matrix to calculate [accuracy,precision,recall]\n","    precision = 0.0\n","    recall = 0.0\n","    f1_score = 0.0\n","    if((conf_matrix[0][0] + conf_matrix[0][1]) != 0):\n","        precision = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[0][1])\n","    if((conf_matrix[0][0] + conf_matrix[1][0]) != 0):\n","        recall = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[1][0])\n","    if((precision + recall) != 0):\n","        f1_score = 2*precision*recall / (precision + recall)\n","    TPR = recall\n","    FPR = conf_matrix[0][1] / (conf_matrix[0][1] + conf_matrix[1][1])\n","    print(\"\\t      Precision: {:<.4f}  -  Recall: {:<.4f}  -  F1 Score: {:<.4f}\".format(precision,recall,f1_score))\n","    return precision,recall,f1_score,TPR,FPR\n","\n","\n","# 混淆矩陣\n","def Confusion_Matrix(result_path,conf_matrix,fold_nums):\n","    # Create the 'confusion_matrix_record' directory if it doesn't exist\n","    confusion_matrix_record_dir = os.path.join(result_path, 'confusion_matrix_record')\n","    plt.clf()\n","    if not os.path.exists(confusion_matrix_record_dir):\n","        os.makedirs(confusion_matrix_record_dir)\n","\n","    confusion_matrix = np.array([[conf_matrix[0][0], conf_matrix[0][1]], [conf_matrix[1][0], conf_matrix[1][1]]])\n","    print(\"Confusion matrix:\")\n","    print(conf_matrix)\n","    plt.imshow(confusion_matrix, cmap=plt.cm.Blues, interpolation='nearest')\n","    plt.colorbar()\n","\n","    # confusion matrix index 各個 index 的數值\n","    for i in range(2):\n","        for j in range(2):\n","            text_color = 'black' if confusion_matrix[i][j] < 0.5 * confusion_matrix.max() else 'white'\n","            plt.annotate(str(confusion_matrix[i][j]), xy=(j, i), ha='center', va='center', color=text_color)\n","    tick_marks = np.arange(2)\n","    plt.xticks(tick_marks, ['Positive', 'Negative'])\n","    plt.yticks(tick_marks, ['Positive', 'Negative'])\n","    plt.ylabel('Predicted Label')\n","    plt.xlabel('True Label')\n","    plt.title('Confusion Matrix')\n","    result_path = result_path + '/confusion_matrix_record'\n","    plt.savefig(os.path.join(result_path,'confusion_matrix_fold'+str(fold_nums + 1)+'.png'))\n","\n","\n","# ROC曲線\n","def ROC_Curve(result_path,tpr_list,fpr_list,fold_nums):\n","    # Create the 'roc_curve_record' directory if it doesn't exist\n","    roc_curve_record_dir = os.path.join(result_path, 'roc_curve_record')\n","    if not os.path.exists(roc_curve_record_dir):\n","        os.makedirs(roc_curve_record_dir)\n","\n","    # 計算 AUC\n","    roc_auc = np.trapz(tpr_list, fpr_list)\n","\n","    # 繪製 ROC 曲線\n","    plt.clf()\n","    plt.plot(fpr_list, tpr_list, lw=1, label='ROC (AUC = %0.2f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], '--', color='gray', label='Random Guessing')\n","    plt.xlim([-0.05, 1.05])\n","    plt.ylim([-0.05, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend()\n","    result_path = result_path + '/roc_curve_record'\n","    plt.savefig(os.path.join(result_path,'Roc_curve'+str(fold_nums + 1)+'.png'))\n","\n","\n","# 輸出每一次 epoch 的結果\n","def CSV_Output(result_path,parameter,num_epochs,train_loss_list,train_acc_list,val_loss_list,val_acc_list,precision_list,recall_list,TPR_list,FPR_list,f1_score_list,fold_wrong_predict,fold_nums):\n","    # Create the 'csv_record' directory if it doesn't exist\n","    csv_record_dir = os.path.join(result_path, 'csv_record')\n","    if not os.path.exists(csv_record_dir):\n","        os.makedirs(csv_record_dir)\n","    with open(result_path + '/csv_record/epoch_fold'+str(fold_nums + 1)+'.csv','w',newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['num_epochs','batch_size','learning_rate','num_classes','device','start_time','end_time','num_fold'])\n","        writer.writerow(parameter)\n","        writer.writerow('')\n","        writer.writerow(['Epoch','train_loss','train_acc','val_loss','val_acc','precision','recall','TPR','FPR','F1 score'])\n","        for epoch in range(num_epochs):\n","            writer.writerow([epoch + 1,\n","                            round(train_loss_list[epoch], 4),\n","                            round(train_acc_list[epoch].item(), 4),\n","                            round(val_loss_list[epoch], 4),\n","                            round(val_acc_list[epoch].item(), 4),\n","                            round(precision_list[epoch], 4),\n","                            round(recall_list[epoch], 4),\n","                            round(TPR_list[epoch], 4),\n","                            round(FPR_list[epoch], 4),\n","                            round(f1_score_list[epoch], 4)])\n","        writer.writerow([f'wrong_predict:',fold_wrong_predict])\n","    print('CSV output Sucessfully')\n","\n","def print_filename_in_txt(train_loader, valid_loader, result_path, fold_num):\n","    # Initialize empty lists to store filenames\n","    train_filenames = []\n","    valid_filenames = []\n","\n","    # Iterate over the training dataset\n","    for batch_idx, (data, target, filename) in enumerate(train_loader):\n","        # Append the filename to the list\n","        train_filenames.extend(filename)\n","\n","    # Iterate over the validation dataset\n","    for batch_idx, (data, target, filename) in enumerate(valid_loader):\n","        # Append the filename to the list\n","        valid_filenames.extend(filename)\n","\n","    # Create the 'file_name_record' directory if it doesn't exist\n","    file_record_dir = os.path.join(result_path, 'file_name_record')\n","    if not os.path.exists(file_record_dir):\n","        os.makedirs(file_record_dir)\n","\n","    # Save the training filenames as a text file\n","    with open(result_path + '/file_name_record/train_filenames_fold_'+str(fold_num + 1)+'.txt', 'w') as file:\n","        for filename in train_filenames:\n","            file.write(filename + '\\n')\n","\n","    # Save the validation filenames as a text file\n","    with open(result_path + '/file_name_record/valid_filenames_fold_'+str(fold_num + 1)+'.txt', 'w') as file:\n","        for filename in valid_filenames:\n","            file.write(filename + '\\n')\n","\n","    print(f\"Filenames saved in {result_path}/train_filenames.txt and {result_path}/valid_filenames.txt\")\n","\n","def calculate_average(avg_train_acc_list, avg_val_acc_list, avg_recall_list, avg_precision_list, avg_f1_score_list, avg_TPR_list, avg_FPR_list, fold_nums, result_path):\n","    # Calculate averages\n","    avg_train_acc = sum(avg_train_acc_list) / fold_nums\n","    avg_val_acc = sum(avg_val_acc_list) / fold_nums\n","    avg_recall = sum(avg_recall_list) / fold_nums\n","    avg_precision = sum(avg_precision_list) / fold_nums\n","    avg_f1_score = sum(avg_f1_score_list) / fold_nums\n","    avg_TPR = sum(avg_TPR_list) / fold_nums\n","    avg_FPR = sum(avg_FPR_list) / fold_nums\n","\n","    # Save averages to a text file\n","    with open(result_path + '/Average.txt', 'w') as file:\n","        file.write(f\"Avg Train Accuracy: {avg_train_acc}\\n\")\n","        file.write(f\"Avg Validation Accuracy: {avg_val_acc}\\n\")\n","        file.write(f\"Avg Recall: {avg_recall}\\n\")\n","        file.write(f\"Avg Precision: {avg_precision}\\n\")\n","        file.write(f\"Avg F1 Score: {avg_f1_score}\\n\")\n","        file.write(f\"Avg TPR: {avg_TPR}\\n\")\n","        file.write(f\"Avg FPR: {avg_FPR}\\n\")\n","\n","    print(f\"Averages saved to {result_path}\")\n","\n","def train(normal_data_dir,abnormal_data_dir,train_normal_tensor_path,train_abnormal_tensor_path,result_path,num_fold):\n","    #超參數設定\n","    batch_size = 66\n","    learning_rate = 0.001\n","    num_epochs = 30\n","    num_classes = 2\n","    num_folds = num_fold\n","    start_time = datetime.now()\n","    end_time = 0\n","    num_argumentation = 20\n","    conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n","\n","    # Get the dataset\n","    train_normal_dataset = MyDataset(train_normal_tensor_path)\n","    train_abnormal_dataset = MyDataset(train_abnormal_tensor_path)\n","    # Combine the datasets\n","    train_datasets = CombinedDataset(train_normal_dataset,train_abnormal_dataset)\n","\n","    # Create the k-fold cross-validation object\n","    kfold = KFold(n_splits=num_folds)\n","\n","    #印出資料集大小\n","    print(\"train dataset's size : \" + str(len(train_datasets)))\n","\n","    #創建模型\n","    model = models.resnet152(pretrained=True)\n","    model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    #print(model)\n","    #print(model.fc)\n","\n","    #將模型移動到GPU上進行運算\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    model.fc.to(device)\n","    print(\"Device used : \" + str(device))\n","\n","    # make dir to save the training outcome\n","    result_path = mkdir_outcome(result_path)\n","\n","    avg_train_acc_list = []\n","    avg_val_acc_list = []\n","    avg_recall_list = []\n","    avg_precision_list = []\n","    avg_f1_score_list = []\n","    avg_TPR_list = []\n","    avg_FPR_list = []\n","\n","    files = []\n","    file_names = os.listdir(normal_data_dir)\n","    for file_name in file_names:\n","        name = os.path.splitext(file_name)[0]\n","        files.append(name)\n","\n","    file_names = os.listdir(abnormal_data_dir)\n","    for file_name in file_names:\n","        name = os.path.splitext(file_name)[0]\n","        files.append(name)\n","\n","    random.shuffle(files)\n","\n","    for fold, (train_indices, valid_indices) in enumerate(kfold.split(files)):\n","        print(f\"Fold: {fold+1}\")\n","\n","        #定義損失函數和優化器\n","        m = nn.Sigmoid()\n","        criterion = nn.BCELoss()\n","        # criterion = nn.CrossEntropyLoss()\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","        train_loss_list = []\n","        train_acc_list = []\n","        val_loss_list = []\n","        val_acc_list = []\n","        recall_list = []\n","        precision_list = []\n","        f1_score_list = []\n","        TPR_list = []\n","        FPR_list = []\n","        fold_wrong_predict = []\n","\n","        train_files = [files[i] for i in train_indices]\n","        valid_files = [files[i] for i in valid_indices]\n","\n","        # 定义用于存储训练集和验证集的文件名的列表\n","        train_data_files = []\n","        valid_data_files = []\n","\n","        # 遍历训练集文件名，根据增强数据的命名规则，找到对应的增强文件名\n","        for file in train_files:\n","            labels, index = file.split('_')\n","            # 构造增强后数据的文件名\n","            for num in range(1,num_argumentation + 1):\n","              augmented_file = f\"{labels}_{index}_aug{num}.pt\"\n","              # 将增强后数据的文件名添加到训练集文件名列表\n","              train_data_files.append(augmented_file)\n","\n","        # 遍历验证集文件名，根据增强数据的命名规则，找到对应的增强文件名\n","        for file in valid_files:\n","            labels, index = file.split('_')\n","            # 构造增强后数据的文件名\n","            for num in range(1,num_argumentation + 1):\n","              augmented_file = f\"{labels}_{index}_aug{num}.pt\"\n","              valid_data_files.append(augmented_file)\n","\n","        train = []\n","        valid = []\n","\n","        # 遍历combined_dataset中的样本索引\n","        for index, (data, labels, filename) in enumerate(train_datasets):\n","            # 检查当前样本的文件名是否在训练集文件名列表中\n","            if filename in train_data_files:\n","                train.append(index)\n","            # 检查当前样本的文件名是否在验证集文件名列表中\n","            elif filename in valid_data_files:\n","                valid.append(index)\n","\n","        # Create the train and validation datasets for this fold\n","        train_dataset = torch.utils.data.Subset(train_datasets, train)\n","        valid_dataset = torch.utils.data.Subset(train_datasets, valid)\n","\n","\n","        print(\"train_dataset : \" + str(len(train_dataset)),\",valid_dataset : \" + str(len(valid_dataset)))\n","\n","        # Create the data loaders for this fold\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","        valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=True, num_workers=4)\n","        print_filename_in_txt(train_loader,valid_loader,result_path,fold)\n","\n","        #訓練模型\n","        for epoch in range(num_epochs):\n","\n","            train_loss = 0\n","            train_correct = 0\n","            train_acc = 0\n","            val_loss = 0\n","            val_corrects = 0\n","            val_acc = 0\n","\n","            print(\"result_path:\" + str(result_path))\n","\n","            if(epoch > 1) :\n","              model.load_state_dict(torch.load(os.path.join(result_path,\"train_fold\"+f'{fold+1}'+\".pt\")))\n","\n","\n","            #初始化\n","            conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n","\n","            print(\"[Training Progress]: \")\n","            model.train()\n","            for inputs, labels, filename in tqdm(train_loader):\n","                targets=torch.eye(2)[labels.long(), :]\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                targets = targets.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                loss = criterion(m(outputs),targets.float())\n","                _, preds = torch.max(outputs, 1)\n","                train_correct += torch.sum(preds == labels.data)\n","                loss.backward()\n","                optimizer.step()\n","                train_loss += loss.item() * inputs.size(0)\n","            train_loss = train_loss / len(train_loader.dataset)\n","            train_acc = train_correct.double() / len(train_loader.dataset)\n","            train_loss_list.append(train_loss)\n","\n","            model.eval()\n","\n","            print(\"[Validating Progress]: \")\n","            wrong_predict = []\n","            for inputs, labels, filename in tqdm(valid_loader):\n","                targets=torch.eye(2)[labels.long(), :]\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                targets = targets.to(device)\n","                with torch.set_grad_enabled(False):\n","                    outputs = model(inputs)\n","                    loss = criterion(m(outputs),targets.float())\n","                val_loss += loss.item() * inputs.size(0)\n","                _, preds = torch.max(outputs, 1)\n","                val_corrects += torch.sum(preds == labels.data)\n","\n","                # Count Confusion Matrix\n","                for t, p in zip(preds.view(-1), labels.view(-1)):\n","                    conf_matrix[t.long(), p.long()] += 1\n","                    if t != p:\n","                      wrong_predict.append(filename)\n","            val_loss = val_loss / len(valid_loader.dataset)\n","            val_acc = val_corrects.double() / len(valid_loader.dataset)\n","            val_loss_list.append(val_loss)\n","\n","            scheduler.step()\n","            end_time = datetime.now()\n","            print('\\nEpoch: [{}/{}]  train_loss: {:<.4f}  -  train_accuracy: {:<.4f} -  val_loss: {:<.4f}  -  val_accuracy: {:<.4f}  -  val_correct: {:<10}'.format(\n","                epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc, val_corrects))\n","            print('wrong predict : ' + str(wrong_predict))\n","            torch.save(model.state_dict(),os.path.join(result_path,\"train_fold\"+f'{fold+1}'+\".pt\"))\n","\n","            # validation index (評估指標)\n","            precision,recall,f1_score,TPR,FPR = validation_index(conf_matrix)\n","\n","            # record the outcomes\n","            val_acc_list.append(val_acc),train_acc_list.append(train_acc),precision_list.append(precision),recall_list.append(recall)\n","            f1_score_list.append(f1_score),TPR_list.append(TPR),FPR_list.append(FPR)\n","\n","            if epoch + 1 == num_epochs:\n","              avg_train_acc_list.append(train_acc),avg_val_acc_list.append(val_acc),avg_recall_list.append(recall),avg_precision_list.append(precision),avg_f1_score_list.append(f1_score),avg_TPR_list.append(TPR),avg_FPR_list.append(FPR),fold_wrong_predict.append(wrong_predict)\n","\n","        # function of confusion matrix param(folder path, matrix, test normal dataset length, test unnormal dataset length)\n","        Confusion_Matrix(result_path,conf_matrix,fold)\n","        # functioN to show ROC curve\n","        ROC_Curve(result_path,TPR_list,FPR_list,fold)\n","        # CSV visualization\n","        param = [num_epochs,batch_size,learning_rate,num_classes,device,start_time,end_time,fold]\n","        CSV_Output(result_path,param,num_epochs,train_loss_list,train_acc_list,val_loss_list,val_acc_list,precision_list,recall_list,TPR_list,FPR_list,f1_score_list,fold_wrong_predict,fold)\n","\n","    #calculate the average\n","    calculate_average(avg_train_acc_list, avg_val_acc_list, avg_recall_list, avg_precision_list, avg_f1_score_list, avg_TPR_list, avg_FPR_list, num_folds, result_path)\n","\n","    torch.cuda.empty_cache()\n","\n","\n","normal_data_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal'\n","abnormal_data_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal'\n","train_normal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/train/normal'\n","train_abnormal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/train/abnormal'\n","result_path = '/content/drive/My Drive/Deep_X_torch/result'\n","\n","train(normal_data_dir,abnormal_data_dir,train_normal_tensor_path,train_abnormal_tensor_path,result_path,5)"]},{"cell_type":"markdown","metadata":{"id":"PJjWpZj2gU-b"},"source":["#訓練及驗證模型(SEResNet)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5755,"status":"ok","timestamp":1697351498396,"user":{"displayName":"陳均葦","userId":"12397795912524578037"},"user_tz":-480},"id":"ExBrYP7Wggzt","outputId":"39c04a7e-2dd9-431c-e3a0-13edb62c9c9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.7)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (17.0.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n"]}],"source":["!pip install timm"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"jI3WItDbf3rO","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8332479ee29e44808ad9087a6dee3ff0","4dd84d86e83442c293831d624d58520b","25989db5badb4447836febf775bdf98a","0b0fae6a8c284412a99b432c5ece2ae3","91e0024f7f384360b57362312e077552","c10a49e1ff024037b1e2bfc423a560ca","ad767b5436214e81991e4ad1f568ed22","3cae6be83e66472983aae617544d86cf","96a9fb7f1105473b825041a46d8b18c6","3582fa04bdfb45febdc04bb8681ad043","d371e6f1d85348d4acec6b1cf30cb9b2"]},"executionInfo":{"status":"error","timestamp":1697351760766,"user_tz":-480,"elapsed":262373,"user":{"displayName":"陳均葦","userId":"12397795912524578037"}},"outputId":"f1acefd6-564c-4023-e37d-5e7eee3f18bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["train dataset's size : 660\n","Fold: 1\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8332479ee29e44808ad9087a6dee3ff0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Device used : cuda\n","train_dataset : 520 ,valid_dataset : 140\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Filenames saved in /content/drive/My Drive/Deep_X_torch/result/result_2/train_2/train_filenames.txt and /content/drive/My Drive/Deep_X_torch/result/result_2/train_2/valid_filenames.txt\n","epoch:1\n","result_path:/content/drive/My Drive/Deep_X_torch/result/result_2/train_2\n","[Training Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:09<01:24,  9.38s/it]\u001b[A\n"," 20%|██        | 2/10 [00:10<00:37,  4.67s/it]\u001b[A\n"," 30%|███       | 3/10 [00:12<00:22,  3.20s/it]\u001b[A\n"," 40%|████      | 4/10 [00:13<00:14,  2.49s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:14<00:10,  2.09s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:16<00:07,  1.85s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:17<00:05,  1.67s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:19<00:03,  1.61s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:20<00:01,  1.51s/it]\u001b[A\n","100%|██████████| 10/10 [00:21<00:00,  2.19s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[Validating Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/140 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/140 [00:00<00:48,  2.89it/s]\u001b[A\n","  3%|▎         | 4/140 [00:00<00:13,  9.96it/s]\u001b[A\n","  5%|▌         | 7/140 [00:00<00:08, 15.01it/s]\u001b[A\n","  7%|▋         | 10/140 [00:00<00:06, 19.14it/s]\u001b[A\n","  9%|▉         | 13/140 [00:00<00:05, 21.98it/s]\u001b[A\n"," 12%|█▏        | 17/140 [00:00<00:04, 25.13it/s]\u001b[A\n"," 14%|█▍        | 20/140 [00:01<00:04, 25.92it/s]\u001b[A\n"," 16%|█▋        | 23/140 [00:01<00:04, 26.86it/s]\u001b[A\n"," 19%|█▉        | 27/140 [00:01<00:04, 28.21it/s]\u001b[A\n"," 21%|██▏       | 30/140 [00:01<00:03, 28.12it/s]\u001b[A\n"," 24%|██▎       | 33/140 [00:01<00:03, 27.87it/s]\u001b[A\n"," 26%|██▌       | 36/140 [00:01<00:03, 27.74it/s]\u001b[A\n"," 28%|██▊       | 39/140 [00:01<00:03, 28.21it/s]\u001b[A\n"," 30%|███       | 42/140 [00:01<00:03, 28.31it/s]\u001b[A\n"," 32%|███▏      | 45/140 [00:01<00:03, 28.30it/s]\u001b[A\n"," 34%|███▍      | 48/140 [00:02<00:03, 28.06it/s]\u001b[A\n"," 37%|███▋      | 52/140 [00:02<00:03, 29.03it/s]\u001b[A\n"," 39%|███▉      | 55/140 [00:02<00:02, 29.03it/s]\u001b[A\n"," 41%|████▏     | 58/140 [00:02<00:02, 29.04it/s]\u001b[A\n"," 44%|████▎     | 61/140 [00:02<00:02, 29.11it/s]\u001b[A\n"," 46%|████▌     | 64/140 [00:02<00:02, 28.53it/s]\u001b[A\n"," 48%|████▊     | 67/140 [00:02<00:02, 28.40it/s]\u001b[A\n"," 50%|█████     | 70/140 [00:02<00:02, 28.65it/s]\u001b[A\n"," 52%|█████▏    | 73/140 [00:02<00:02, 28.66it/s]\u001b[A\n"," 54%|█████▍    | 76/140 [00:02<00:02, 28.60it/s]\u001b[A\n"," 56%|█████▋    | 79/140 [00:03<00:02, 28.52it/s]\u001b[A\n"," 59%|█████▉    | 83/140 [00:03<00:01, 29.52it/s]\u001b[A\n"," 61%|██████▏   | 86/140 [00:03<00:01, 29.49it/s]\u001b[A\n"," 64%|██████▎   | 89/140 [00:03<00:02, 24.95it/s]\u001b[A\n"," 66%|██████▌   | 92/140 [00:03<00:01, 25.50it/s]\u001b[A\n"," 68%|██████▊   | 95/140 [00:03<00:01, 26.31it/s]\u001b[A\n"," 70%|███████   | 98/140 [00:03<00:01, 26.94it/s]\u001b[A\n"," 72%|███████▏  | 101/140 [00:03<00:01, 26.93it/s]\u001b[A\n"," 74%|███████▍  | 104/140 [00:04<00:01, 27.32it/s]\u001b[A\n"," 76%|███████▋  | 107/140 [00:04<00:01, 28.03it/s]\u001b[A\n"," 79%|███████▊  | 110/140 [00:04<00:01, 28.12it/s]\u001b[A\n"," 81%|████████  | 113/140 [00:04<00:00, 28.60it/s]\u001b[A\n"," 83%|████████▎ | 116/140 [00:04<00:00, 24.70it/s]\u001b[A\n"," 85%|████████▌ | 119/140 [00:04<00:00, 21.99it/s]\u001b[A\n"," 87%|████████▋ | 122/140 [00:04<00:00, 21.87it/s]\u001b[A\n"," 89%|████████▉ | 125/140 [00:04<00:00, 21.58it/s]\u001b[A\n"," 91%|█████████▏| 128/140 [00:05<00:00, 21.68it/s]\u001b[A\n"," 94%|█████████▎| 131/140 [00:05<00:00, 21.13it/s]\u001b[A\n"," 96%|█████████▌| 134/140 [00:05<00:00, 21.62it/s]\u001b[A\n"," 98%|█████████▊| 137/140 [00:05<00:00, 21.44it/s]\u001b[A\n","100%|██████████| 140/140 [00:05<00:00, 23.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch: [1/20]  train_loss: 0.2686  -  train_accuracy: 0.8462 -  val_loss: 6.4149  -  val_accuracy: 0.7929  -  val_correct: 111       \n","wrong predict : [('normal_1_aug15.pt',), ('normal_1_aug16.pt',), ('normal_1_aug14.pt',), ('normal_1_aug19.pt',), ('normal_1_aug2.pt',), ('abnormal_9_aug7.pt',), ('normal_1_aug8.pt',), ('normal_1_aug10.pt',), ('normal_1_aug12.pt',), ('normal_1_aug20.pt',), ('normal_1_aug3.pt',), ('abnormal_9_aug14.pt',), ('normal_1_aug4.pt',), ('normal_1_aug1.pt',), ('abnormal_9_aug3.pt',), ('normal_1_aug13.pt',), ('abnormal_9_aug8.pt',), ('normal_1_aug5.pt',), ('abnormal_9_aug12.pt',), ('normal_1_aug11.pt',), ('normal_1_aug18.pt',), ('normal_5_aug10.pt',), ('normal_1_aug7.pt',), ('abnormal_9_aug16.pt',), ('normal_1_aug9.pt',), ('normal_1_aug6.pt',), ('normal_1_aug17.pt',), ('abnormal_9_aug15.pt',), ('abnormal_9_aug11.pt',)]\n","Model saved\n","\t      Precision: 0.8806  -  Recall: 0.7375  -  F1 Score: 0.8027\n","epoch:2\n","result_path:/content/drive/My Drive/Deep_X_torch/result/result_2/train_2\n","Model loaded\n","[Training Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:01<00:16,  1.88s/it]\u001b[A\n"," 20%|██        | 2/10 [00:03<00:12,  1.54s/it]\u001b[A\n"," 30%|███       | 3/10 [00:04<00:10,  1.51s/it]\u001b[A\n"," 40%|████      | 4/10 [00:05<00:08,  1.43s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:07<00:06,  1.39s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:08<00:05,  1.36s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:09<00:04,  1.34s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:11<00:02,  1.32s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:12<00:01,  1.32s/it]\u001b[A\n","100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[Validating Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/140 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/140 [00:00<00:57,  2.41it/s]\u001b[A\n","  2%|▏         | 3/140 [00:00<00:20,  6.56it/s]\u001b[A\n","  4%|▎         | 5/140 [00:00<00:14,  9.53it/s]\u001b[A\n","  5%|▌         | 7/140 [00:00<00:11, 11.70it/s]\u001b[A\n","  6%|▋         | 9/140 [00:00<00:10, 12.77it/s]\u001b[A\n","  8%|▊         | 11/140 [00:01<00:09, 13.66it/s]\u001b[A\n","  9%|▉         | 13/140 [00:01<00:08, 15.19it/s]\u001b[A\n"," 11%|█▏        | 16/140 [00:01<00:06, 18.31it/s]\u001b[A\n"," 14%|█▎        | 19/140 [00:01<00:05, 21.23it/s]\u001b[A\n"," 16%|█▌        | 22/140 [00:01<00:05, 22.86it/s]\u001b[A\n"," 18%|█▊        | 25/140 [00:01<00:04, 24.30it/s]\u001b[A\n"," 20%|██        | 28/140 [00:01<00:04, 25.70it/s]\u001b[A\n"," 22%|██▏       | 31/140 [00:01<00:04, 26.26it/s]\u001b[A\n"," 24%|██▍       | 34/140 [00:01<00:03, 26.81it/s]\u001b[A\n"," 26%|██▋       | 37/140 [00:02<00:03, 27.02it/s]\u001b[A\n"," 29%|██▊       | 40/140 [00:02<00:03, 27.39it/s]\u001b[A\n"," 31%|███       | 43/140 [00:02<00:03, 27.02it/s]\u001b[A\n"," 33%|███▎      | 46/140 [00:02<00:03, 27.04it/s]\u001b[A\n"," 35%|███▌      | 49/140 [00:02<00:03, 27.41it/s]\u001b[A\n"," 37%|███▋      | 52/140 [00:02<00:03, 27.15it/s]\u001b[A\n"," 39%|███▉      | 55/140 [00:02<00:03, 27.91it/s]\u001b[A\n"," 42%|████▏     | 59/140 [00:02<00:03, 26.27it/s]\u001b[A\n"," 44%|████▍     | 62/140 [00:03<00:03, 20.25it/s]\u001b[A\n"," 46%|████▋     | 65/140 [00:03<00:03, 21.34it/s]\u001b[A\n"," 49%|████▊     | 68/140 [00:03<00:03, 22.67it/s]\u001b[A\n"," 51%|█████     | 71/140 [00:03<00:03, 19.85it/s]\u001b[A\n"," 53%|█████▎    | 74/140 [00:03<00:03, 19.63it/s]\u001b[A\n"," 55%|█████▌    | 77/140 [00:03<00:02, 21.19it/s]\u001b[A\n"," 57%|█████▋    | 80/140 [00:03<00:02, 22.49it/s]\u001b[A\n"," 59%|█████▉    | 83/140 [00:03<00:02, 23.54it/s]\u001b[A\n"," 61%|██████▏   | 86/140 [00:04<00:02, 24.75it/s]\u001b[A\n"," 64%|██████▎   | 89/140 [00:04<00:01, 25.76it/s]\u001b[A\n"," 66%|██████▌   | 92/140 [00:04<00:01, 25.41it/s]\u001b[A\n"," 68%|██████▊   | 95/140 [00:04<00:01, 26.32it/s]\u001b[A\n"," 70%|███████   | 98/140 [00:04<00:01, 26.06it/s]\u001b[A\n"," 72%|███████▏  | 101/140 [00:04<00:01, 26.65it/s]\u001b[A\n"," 74%|███████▍  | 104/140 [00:04<00:01, 27.51it/s]\u001b[A\n"," 76%|███████▋  | 107/140 [00:04<00:01, 27.50it/s]\u001b[A\n"," 79%|███████▊  | 110/140 [00:04<00:01, 27.86it/s]\u001b[A\n"," 81%|████████  | 113/140 [00:05<00:01, 26.61it/s]\u001b[A\n"," 83%|████████▎ | 116/140 [00:05<00:00, 27.08it/s]\u001b[A\n"," 85%|████████▌ | 119/140 [00:05<00:00, 26.44it/s]\u001b[A\n"," 87%|████████▋ | 122/140 [00:05<00:00, 26.92it/s]\u001b[A\n"," 89%|████████▉ | 125/140 [00:05<00:00, 26.74it/s]\u001b[A\n"," 91%|█████████▏| 128/140 [00:05<00:00, 27.56it/s]\u001b[A\n"," 94%|█████████▎| 131/140 [00:05<00:00, 27.28it/s]\u001b[A\n"," 96%|█████████▌| 134/140 [00:05<00:00, 27.44it/s]\u001b[A\n"," 98%|█████████▊| 137/140 [00:05<00:00, 27.49it/s]\u001b[A\n","100%|██████████| 140/140 [00:06<00:00, 22.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch: [2/20]  train_loss: 0.0197  -  train_accuracy: 0.9942 -  val_loss: 5.7587  -  val_accuracy: 0.7357  -  val_correct: 103       \n","wrong predict : [('normal_1_aug3.pt',), ('normal_1_aug8.pt',), ('abnormal_9_aug5.pt',), ('abnormal_9_aug19.pt',), ('normal_1_aug6.pt',), ('normal_1_aug13.pt',), ('abnormal_9_aug2.pt',), ('abnormal_9_aug6.pt',), ('abnormal_9_aug9.pt',), ('abnormal_9_aug7.pt',), ('normal_1_aug7.pt',), ('abnormal_9_aug17.pt',), ('normal_5_aug10.pt',), ('abnormal_9_aug15.pt',), ('normal_1_aug15.pt',), ('abnormal_9_aug1.pt',), ('abnormal_9_aug16.pt',), ('normal_1_aug16.pt',), ('abnormal_9_aug8.pt',), ('normal_1_aug1.pt',), ('abnormal_9_aug12.pt',), ('abnormal_9_aug20.pt',), ('normal_1_aug2.pt',), ('normal_1_aug5.pt',), ('abnormal_9_aug3.pt',), ('normal_1_aug10.pt',), ('abnormal_9_aug4.pt',), ('abnormal_9_aug10.pt',), ('abnormal_9_aug11.pt',), ('normal_1_aug4.pt',), ('abnormal_9_aug14.pt',), ('normal_1_aug20.pt',), ('abnormal_9_aug18.pt',), ('normal_1_aug14.pt',), ('normal_1_aug9.pt',), ('abnormal_9_aug13.pt',), ('normal_1_aug12.pt',)]\n","Model saved\n","\t      Precision: 0.7590  -  Recall: 0.7875  -  F1 Score: 0.7730\n","epoch:3\n","result_path:/content/drive/My Drive/Deep_X_torch/result/result_2/train_2\n","Model loaded\n","[Training Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:01<00:15,  1.73s/it]\u001b[A\n"," 20%|██        | 2/10 [00:03<00:11,  1.48s/it]\u001b[A\n"," 30%|███       | 3/10 [00:04<00:09,  1.40s/it]\u001b[A\n"," 40%|████      | 4/10 [00:05<00:08,  1.36s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:06<00:06,  1.34s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:08<00:05,  1.33s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:09<00:03,  1.32s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:10<00:02,  1.32s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:12<00:01,  1.31s/it]\u001b[A\n","100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[Validating Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/140 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/140 [00:00<00:41,  3.36it/s]\u001b[A\n","  3%|▎         | 4/140 [00:00<00:12, 11.27it/s]\u001b[A\n","  5%|▌         | 7/140 [00:00<00:07, 16.73it/s]\u001b[A\n","  7%|▋         | 10/140 [00:00<00:06, 20.30it/s]\u001b[A\n","  9%|▉         | 13/140 [00:00<00:05, 22.58it/s]\u001b[A\n"," 11%|█▏        | 16/140 [00:00<00:05, 24.52it/s]\u001b[A\n"," 14%|█▎        | 19/140 [00:00<00:04, 24.70it/s]\u001b[A\n"," 16%|█▌        | 22/140 [00:01<00:04, 25.88it/s]\u001b[A\n"," 18%|█▊        | 25/140 [00:01<00:04, 26.41it/s]\u001b[A\n"," 20%|██        | 28/140 [00:01<00:04, 26.66it/s]\u001b[A\n"," 22%|██▏       | 31/140 [00:01<00:03, 27.25it/s]\u001b[A\n"," 24%|██▍       | 34/140 [00:01<00:03, 26.93it/s]\u001b[A\n"," 26%|██▋       | 37/140 [00:01<00:03, 27.36it/s]\u001b[A\n"," 29%|██▊       | 40/140 [00:01<00:03, 27.51it/s]\u001b[A\n"," 31%|███       | 43/140 [00:01<00:03, 27.75it/s]\u001b[A\n"," 33%|███▎      | 46/140 [00:01<00:03, 27.16it/s]\u001b[A\n"," 35%|███▌      | 49/140 [00:02<00:03, 27.68it/s]\u001b[A\n"," 37%|███▋      | 52/140 [00:02<00:03, 27.36it/s]\u001b[A\n"," 39%|███▉      | 55/140 [00:02<00:03, 27.47it/s]\u001b[A\n"," 41%|████▏     | 58/140 [00:02<00:02, 27.71it/s]\u001b[A\n"," 44%|████▎     | 61/140 [00:02<00:02, 28.25it/s]\u001b[A\n"," 46%|████▌     | 64/140 [00:02<00:02, 28.36it/s]\u001b[A\n"," 48%|████▊     | 67/140 [00:02<00:02, 28.21it/s]\u001b[A\n"," 50%|█████     | 70/140 [00:02<00:02, 28.61it/s]\u001b[A\n"," 52%|█████▏    | 73/140 [00:02<00:02, 28.68it/s]\u001b[A\n"," 54%|█████▍    | 76/140 [00:03<00:02, 27.33it/s]\u001b[A\n"," 56%|█████▋    | 79/140 [00:03<00:02, 27.64it/s]\u001b[A\n"," 59%|█████▊    | 82/140 [00:03<00:02, 26.10it/s]\u001b[A\n"," 61%|██████    | 85/140 [00:03<00:02, 25.22it/s]\u001b[A\n"," 63%|██████▎   | 88/140 [00:03<00:01, 26.30it/s]\u001b[A\n"," 65%|██████▌   | 91/140 [00:03<00:01, 27.03it/s]\u001b[A\n"," 67%|██████▋   | 94/140 [00:03<00:01, 27.46it/s]\u001b[A\n"," 69%|██████▉   | 97/140 [00:03<00:01, 23.78it/s]\u001b[A\n"," 71%|███████▏  | 100/140 [00:04<00:01, 21.99it/s]\u001b[A\n"," 74%|███████▎  | 103/140 [00:04<00:01, 21.30it/s]\u001b[A\n"," 76%|███████▌  | 106/140 [00:04<00:01, 21.33it/s]\u001b[A\n"," 78%|███████▊  | 109/140 [00:04<00:01, 20.78it/s]\u001b[A\n"," 80%|████████  | 112/140 [00:04<00:01, 20.30it/s]\u001b[A\n"," 82%|████████▏ | 115/140 [00:04<00:01, 20.13it/s]\u001b[A\n"," 84%|████████▍ | 118/140 [00:05<00:01, 17.19it/s]\u001b[A\n"," 86%|████████▌ | 120/140 [00:05<00:01, 17.41it/s]\u001b[A\n"," 87%|████████▋ | 122/140 [00:05<00:01, 17.48it/s]\u001b[A\n"," 89%|████████▊ | 124/140 [00:05<00:00, 18.03it/s]\u001b[A\n"," 90%|█████████ | 126/140 [00:05<00:00, 18.39it/s]\u001b[A\n"," 91%|█████████▏| 128/140 [00:05<00:00, 18.80it/s]\u001b[A\n"," 93%|█████████▎| 130/140 [00:05<00:00, 18.90it/s]\u001b[A\n"," 95%|█████████▌| 133/140 [00:05<00:00, 19.71it/s]\u001b[A\n"," 97%|█████████▋| 136/140 [00:05<00:00, 20.44it/s]\u001b[A\n","100%|██████████| 140/140 [00:06<00:00, 21.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch: [3/20]  train_loss: 0.0218  -  train_accuracy: 0.9962 -  val_loss: 1.3686  -  val_accuracy: 0.8357  -  val_correct: 117       \n","wrong predict : [('normal_1_aug18.pt',), ('normal_1_aug12.pt',), ('normal_1_aug16.pt',), ('normal_1_aug2.pt',), ('normal_1_aug15.pt',), ('normal_7_aug7.pt',), ('normal_1_aug9.pt',), ('normal_1_aug14.pt',), ('normal_1_aug20.pt',), ('normal_1_aug3.pt',), ('normal_1_aug17.pt',), ('normal_1_aug10.pt',), ('abnormal_9_aug15.pt',), ('normal_1_aug8.pt',), ('normal_1_aug6.pt',), ('normal_1_aug11.pt',), ('abnormal_9_aug16.pt',), ('normal_1_aug13.pt',), ('normal_1_aug5.pt',), ('normal_1_aug4.pt',), ('normal_1_aug7.pt',), ('normal_1_aug1.pt',), ('normal_1_aug19.pt',)]\n","Model saved\n","\t      Precision: 0.9672  -  Recall: 0.7375  -  F1 Score: 0.8369\n","epoch:4\n","result_path:/content/drive/My Drive/Deep_X_torch/result/result_2/train_2\n","Model loaded\n","[Training Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:01<00:15,  1.73s/it]\u001b[A\n"," 20%|██        | 2/10 [00:03<00:11,  1.49s/it]\u001b[A\n"," 30%|███       | 3/10 [00:04<00:09,  1.41s/it]\u001b[A\n"," 40%|████      | 4/10 [00:05<00:08,  1.37s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:06<00:06,  1.35s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:08<00:05,  1.33s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:09<00:03,  1.33s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:10<00:02,  1.33s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:12<00:01,  1.33s/it]\u001b[A\n","100%|██████████| 10/10 [00:13<00:00,  1.39s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[Validating Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/140 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/140 [00:00<00:55,  2.49it/s]\u001b[A\n","  2%|▏         | 3/140 [00:00<00:22,  6.22it/s]\u001b[A\n","  4%|▎         | 5/140 [00:00<00:14,  9.12it/s]\u001b[A\n","  5%|▌         | 7/140 [00:00<00:11, 11.25it/s]\u001b[A\n","  6%|▋         | 9/140 [00:00<00:10, 12.44it/s]\u001b[A\n","  8%|▊         | 11/140 [00:01<00:09, 13.25it/s]\u001b[A\n","  9%|▉         | 13/140 [00:01<00:09, 12.84it/s]\u001b[A\n"," 11%|█         | 15/140 [00:01<00:09, 13.63it/s]\u001b[A\n"," 12%|█▏        | 17/140 [00:01<00:08, 14.09it/s]\u001b[A\n"," 14%|█▎        | 19/140 [00:01<00:08, 14.06it/s]\u001b[A\n"," 15%|█▌        | 21/140 [00:01<00:08, 13.55it/s]\u001b[A\n"," 16%|█▋        | 23/140 [00:01<00:08, 13.21it/s]\u001b[A\n"," 18%|█▊        | 25/140 [00:02<00:08, 12.96it/s]\u001b[A\n"," 19%|█▉        | 27/140 [00:02<00:10, 11.01it/s]\u001b[A\n"," 21%|██        | 29/140 [00:02<00:11,  9.96it/s]\u001b[A\n"," 22%|██▏       | 31/140 [00:02<00:11,  9.85it/s]\u001b[A\n"," 24%|██▎       | 33/140 [00:03<00:11,  9.66it/s]\u001b[A\n"," 24%|██▍       | 34/140 [00:03<00:11,  9.14it/s]\u001b[A\n"," 25%|██▌       | 35/140 [00:03<00:11,  8.87it/s]\u001b[A\n"," 26%|██▋       | 37/140 [00:03<00:10, 10.05it/s]\u001b[A\n"," 28%|██▊       | 39/140 [00:03<00:09, 10.12it/s]\u001b[A\n"," 29%|██▉       | 41/140 [00:03<00:10,  9.20it/s]\u001b[A\n"," 31%|███       | 43/140 [00:04<00:09,  9.90it/s]\u001b[A\n"," 32%|███▏      | 45/140 [00:04<00:09,  9.75it/s]\u001b[A\n"," 34%|███▎      | 47/140 [00:04<00:09,  9.99it/s]\u001b[A\n"," 35%|███▌      | 49/140 [00:04<00:08, 10.40it/s]\u001b[A\n"," 36%|███▋      | 51/140 [00:04<00:07, 11.15it/s]\u001b[A\n"," 38%|███▊      | 53/140 [00:04<00:08, 10.85it/s]\u001b[A\n"," 39%|███▉      | 55/140 [00:05<00:07, 11.05it/s]\u001b[A\n"," 41%|████      | 57/140 [00:05<00:07, 10.51it/s]\u001b[A\n"," 42%|████▏     | 59/140 [00:05<00:07, 10.75it/s]\u001b[A\n"," 44%|████▎     | 61/140 [00:05<00:06, 11.71it/s]\u001b[A\n"," 45%|████▌     | 63/140 [00:05<00:06, 12.78it/s]\u001b[A\n"," 46%|████▋     | 65/140 [00:05<00:05, 12.88it/s]\u001b[A\n"," 48%|████▊     | 67/140 [00:06<00:06, 12.04it/s]\u001b[A\n"," 49%|████▉     | 69/140 [00:06<00:06, 10.54it/s]\u001b[A\n"," 51%|█████     | 71/140 [00:06<00:07,  9.79it/s]\u001b[A\n"," 52%|█████▏    | 73/140 [00:06<00:07,  9.14it/s]\u001b[A\n"," 53%|█████▎    | 74/140 [00:07<00:07,  8.92it/s]\u001b[A\n"," 54%|█████▍    | 76/140 [00:07<00:06, 10.14it/s]\u001b[A\n"," 56%|█████▌    | 78/140 [00:07<00:05, 11.52it/s]\u001b[A\n"," 57%|█████▋    | 80/140 [00:07<00:05, 11.42it/s]\u001b[A\n"," 59%|█████▊    | 82/140 [00:07<00:05, 10.80it/s]\u001b[A\n"," 60%|██████    | 84/140 [00:07<00:04, 11.62it/s]\u001b[A\n"," 61%|██████▏   | 86/140 [00:08<00:04, 10.84it/s]\u001b[A\n"," 63%|██████▎   | 88/140 [00:08<00:04, 10.70it/s]\u001b[A\n"," 64%|██████▍   | 90/140 [00:08<00:04, 11.18it/s]\u001b[A\n"," 66%|██████▌   | 92/140 [00:08<00:04, 11.41it/s]\u001b[A\n"," 67%|██████▋   | 94/140 [00:08<00:04, 10.56it/s]\u001b[A\n"," 69%|██████▊   | 96/140 [00:09<00:04,  9.74it/s]\u001b[A\n"," 70%|███████   | 98/140 [00:09<00:04,  8.98it/s]\u001b[A\n"," 71%|███████   | 99/140 [00:09<00:04,  8.61it/s]\u001b[A\n"," 71%|███████▏  | 100/140 [00:09<00:05,  7.75it/s]\u001b[A\n"," 72%|███████▏  | 101/140 [00:09<00:05,  7.30it/s]\u001b[A\n"," 73%|███████▎  | 102/140 [00:09<00:05,  7.52it/s]\u001b[A\n"," 74%|███████▎  | 103/140 [00:10<00:04,  7.64it/s]\u001b[A\n"," 74%|███████▍  | 104/140 [00:10<00:04,  7.42it/s]\u001b[A\n"," 75%|███████▌  | 105/140 [00:10<00:05,  6.01it/s]\u001b[A\n"," 76%|███████▌  | 106/140 [00:10<00:05,  5.88it/s]\u001b[A\n"," 76%|███████▋  | 107/140 [00:10<00:05,  5.87it/s]\u001b[A\n"," 77%|███████▋  | 108/140 [00:11<00:06,  4.76it/s]\u001b[A\n"," 78%|███████▊  | 109/140 [00:11<00:10,  3.08it/s]\u001b[A\n"," 79%|███████▊  | 110/140 [00:12<00:11,  2.71it/s]\u001b[A\n"," 79%|███████▉  | 111/140 [00:12<00:10,  2.81it/s]\u001b[A\n"," 80%|████████  | 112/140 [00:12<00:09,  2.91it/s]\u001b[A\n"," 81%|████████  | 113/140 [00:13<00:08,  3.03it/s]\u001b[A\n"," 81%|████████▏ | 114/140 [00:13<00:08,  3.12it/s]\u001b[A\n"," 82%|████████▏ | 115/140 [00:13<00:07,  3.27it/s]\u001b[A\n"," 83%|████████▎ | 116/140 [00:13<00:06,  3.91it/s]\u001b[A\n"," 84%|████████▎ | 117/140 [00:13<00:05,  4.41it/s]\u001b[A\n"," 85%|████████▌ | 119/140 [00:14<00:03,  6.01it/s]\u001b[A\n"," 86%|████████▌ | 120/140 [00:14<00:03,  6.20it/s]\u001b[A\n"," 86%|████████▋ | 121/140 [00:14<00:02,  6.69it/s]\u001b[A\n"," 87%|████████▋ | 122/140 [00:14<00:02,  6.56it/s]\u001b[A\n"," 88%|████████▊ | 123/140 [00:14<00:02,  7.10it/s]\u001b[A\n"," 89%|████████▊ | 124/140 [00:14<00:02,  7.19it/s]\u001b[A\n"," 89%|████████▉ | 125/140 [00:14<00:02,  7.23it/s]\u001b[A\n"," 90%|█████████ | 126/140 [00:15<00:01,  7.06it/s]\u001b[A\n"," 91%|█████████ | 127/140 [00:15<00:01,  7.19it/s]\u001b[A\n"," 91%|█████████▏| 128/140 [00:15<00:01,  7.49it/s]\u001b[A\n"," 92%|█████████▏| 129/140 [00:15<00:01,  6.61it/s]\u001b[A\n"," 93%|█████████▎| 130/140 [00:15<00:01,  6.27it/s]\u001b[A\n"," 94%|█████████▎| 131/140 [00:15<00:01,  6.67it/s]\u001b[A\n"," 94%|█████████▍| 132/140 [00:15<00:01,  7.29it/s]\u001b[A\n"," 95%|█████████▌| 133/140 [00:16<00:00,  7.20it/s]\u001b[A\n"," 96%|█████████▋| 135/140 [00:16<00:00,  8.03it/s]\u001b[A\n"," 98%|█████████▊| 137/140 [00:16<00:00,  9.23it/s]\u001b[A\n","100%|██████████| 140/140 [00:16<00:00,  8.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch: [4/20]  train_loss: 0.0266  -  train_accuracy: 0.9962 -  val_loss: 3.6082  -  val_accuracy: 0.7000  -  val_correct: 98        \n","wrong predict : [('normal_1_aug11.pt',), ('normal_1_aug12.pt',), ('normal_7_aug16.pt',), ('normal_1_aug3.pt',), ('normal_7_aug19.pt',), ('normal_7_aug3.pt',), ('normal_1_aug18.pt',), ('normal_1_aug9.pt',), ('normal_1_aug19.pt',), ('normal_1_aug1.pt',), ('normal_7_aug10.pt',), ('normal_1_aug15.pt',), ('normal_1_aug17.pt',), ('normal_7_aug18.pt',), ('normal_7_aug15.pt',), ('normal_7_aug4.pt',), ('normal_7_aug20.pt',), ('normal_7_aug12.pt',), ('normal_1_aug10.pt',), ('normal_1_aug4.pt',), ('normal_7_aug11.pt',), ('normal_7_aug1.pt',), ('normal_1_aug7.pt',), ('normal_7_aug13.pt',), ('normal_1_aug14.pt',), ('normal_1_aug6.pt',), ('normal_5_aug4.pt',), ('normal_1_aug2.pt',), ('normal_7_aug9.pt',), ('normal_1_aug20.pt',), ('normal_5_aug20.pt',), ('normal_7_aug7.pt',), ('normal_1_aug8.pt',), ('normal_7_aug17.pt',), ('normal_1_aug13.pt',), ('normal_1_aug16.pt',), ('normal_5_aug10.pt',), ('normal_1_aug5.pt',), ('normal_7_aug8.pt',), ('normal_7_aug2.pt',), ('normal_7_aug5.pt',), ('normal_7_aug14.pt',)]\n","Model saved\n","\t      Precision: 1.0000  -  Recall: 0.4750  -  F1 Score: 0.6441\n","epoch:5\n","result_path:/content/drive/My Drive/Deep_X_torch/result/result_2/train_2\n","Model loaded\n","[Training Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:02<00:19,  2.15s/it]\u001b[A\n"," 20%|██        | 2/10 [00:03<00:13,  1.66s/it]\u001b[A\n"," 30%|███       | 3/10 [00:04<00:10,  1.51s/it]\u001b[A\n"," 40%|████      | 4/10 [00:06<00:08,  1.43s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:07<00:06,  1.39s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:08<00:05,  1.37s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:10<00:04,  1.36s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:11<00:02,  1.35s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:12<00:01,  1.34s/it]\u001b[A\n","100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[Validating Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/140 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/140 [00:00<00:39,  3.50it/s]\u001b[A\n","  3%|▎         | 4/140 [00:00<00:11, 11.98it/s]\u001b[A\n","  5%|▌         | 7/140 [00:00<00:07, 17.47it/s]\u001b[A\n","  7%|▋         | 10/140 [00:00<00:06, 20.81it/s]\u001b[A\n","  9%|▉         | 13/140 [00:00<00:05, 23.05it/s]\u001b[A\n"," 11%|█▏        | 16/140 [00:00<00:05, 24.78it/s]\u001b[A\n"," 14%|█▎        | 19/140 [00:00<00:05, 23.61it/s]\u001b[A\n"," 16%|█▌        | 22/140 [00:01<00:04, 24.95it/s]\u001b[A\n"," 18%|█▊        | 25/140 [00:01<00:04, 25.71it/s]\u001b[A\n"," 20%|██        | 28/140 [00:01<00:04, 26.38it/s]\u001b[A\n"," 22%|██▏       | 31/140 [00:01<00:04, 27.00it/s]\u001b[A\n"," 25%|██▌       | 35/140 [00:01<00:03, 28.03it/s]\u001b[A\n"," 27%|██▋       | 38/140 [00:01<00:03, 28.18it/s]\u001b[A\n"," 29%|██▉       | 41/140 [00:01<00:03, 28.48it/s]\u001b[A\n"," 31%|███▏      | 44/140 [00:01<00:03, 28.28it/s]\u001b[A\n"," 34%|███▎      | 47/140 [00:01<00:03, 27.46it/s]\u001b[A\n"," 36%|███▌      | 50/140 [00:02<00:03, 27.91it/s]\u001b[A\n"," 38%|███▊      | 53/140 [00:02<00:03, 27.97it/s]\u001b[A\n"," 40%|████      | 56/140 [00:02<00:02, 28.45it/s]\u001b[A\n"," 42%|████▏     | 59/140 [00:02<00:02, 27.55it/s]\u001b[A\n"," 44%|████▍     | 62/140 [00:02<00:02, 27.88it/s]\u001b[A\n"," 46%|████▋     | 65/140 [00:02<00:02, 27.26it/s]\u001b[A\n"," 49%|████▊     | 68/140 [00:02<00:02, 27.11it/s]\u001b[A\n"," 51%|█████     | 71/140 [00:02<00:02, 27.69it/s]\u001b[A\n"," 53%|█████▎    | 74/140 [00:02<00:02, 26.81it/s]\u001b[A\n"," 55%|█████▌    | 77/140 [00:03<00:02, 27.49it/s]\u001b[A\n"," 57%|█████▋    | 80/140 [00:03<00:02, 27.76it/s]\u001b[A\n"," 59%|█████▉    | 83/140 [00:03<00:02, 27.61it/s]\u001b[A\n"," 61%|██████▏   | 86/140 [00:03<00:01, 27.85it/s]\u001b[A\n"," 64%|██████▎   | 89/140 [00:03<00:01, 27.39it/s]\u001b[A\n"," 66%|██████▌   | 92/140 [00:03<00:01, 27.34it/s]\u001b[A\n"," 68%|██████▊   | 95/140 [00:03<00:01, 27.82it/s]\u001b[A\n"," 70%|███████   | 98/140 [00:03<00:01, 28.00it/s]\u001b[A\n"," 72%|███████▏  | 101/140 [00:03<00:01, 27.26it/s]\u001b[A\n"," 74%|███████▍  | 104/140 [00:04<00:01, 27.20it/s]\u001b[A\n"," 76%|███████▋  | 107/140 [00:04<00:01, 26.81it/s]\u001b[A\n"," 79%|███████▉  | 111/140 [00:04<00:01, 28.22it/s]\u001b[A\n"," 81%|████████▏ | 114/140 [00:04<00:00, 28.20it/s]\u001b[A\n"," 84%|████████▎ | 117/140 [00:04<00:00, 28.17it/s]\u001b[A\n"," 86%|████████▌ | 120/140 [00:04<00:00, 28.53it/s]\u001b[A\n"," 88%|████████▊ | 123/140 [00:04<00:00, 28.40it/s]\u001b[A\n"," 90%|█████████ | 126/140 [00:04<00:00, 28.33it/s]\u001b[A\n"," 92%|█████████▏| 129/140 [00:04<00:00, 28.72it/s]\u001b[A\n"," 94%|█████████▍| 132/140 [00:05<00:00, 27.52it/s]\u001b[A\n"," 96%|█████████▋| 135/140 [00:05<00:00, 28.19it/s]\u001b[A\n","100%|██████████| 140/140 [00:05<00:00, 25.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch: [5/20]  train_loss: 0.0173  -  train_accuracy: 0.9942 -  val_loss: 1.6045  -  val_accuracy: 0.7500  -  val_correct: 105       \n","wrong predict : [('normal_5_aug18.pt',), ('normal_5_aug6.pt',), ('normal_1_aug7.pt',), ('normal_5_aug10.pt',), ('normal_5_aug12.pt',), ('normal_1_aug2.pt',), ('normal_1_aug10.pt',), ('normal_5_aug16.pt',), ('normal_1_aug18.pt',), ('normal_5_aug11.pt',), ('normal_1_aug14.pt',), ('normal_1_aug9.pt',), ('normal_1_aug8.pt',), ('normal_1_aug3.pt',), ('normal_1_aug19.pt',), ('normal_5_aug13.pt',), ('normal_7_aug7.pt',), ('normal_1_aug5.pt',), ('normal_1_aug17.pt',), ('normal_5_aug8.pt',), ('normal_1_aug4.pt',), ('normal_1_aug1.pt',), ('normal_1_aug12.pt',), ('normal_1_aug16.pt',), ('normal_5_aug9.pt',), ('normal_1_aug6.pt',), ('normal_9_aug19.pt',), ('normal_1_aug13.pt',), ('normal_1_aug20.pt',), ('normal_7_aug12.pt',), ('normal_5_aug4.pt',), ('normal_1_aug11.pt',), ('normal_5_aug3.pt',), ('normal_1_aug15.pt',), ('normal_5_aug19.pt',)]\n","Model saved\n","\t      Precision: 1.0000  -  Recall: 0.5625  -  F1 Score: 0.7200\n","epoch:6\n","result_path:/content/drive/My Drive/Deep_X_torch/result/result_2/train_2\n","Model loaded\n","[Training Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:01<00:17,  1.90s/it]\u001b[A\n"," 20%|██        | 2/10 [00:03<00:12,  1.58s/it]\u001b[A\n"," 30%|███       | 3/10 [00:04<00:10,  1.46s/it]\u001b[A\n"," 40%|████      | 4/10 [00:05<00:08,  1.41s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:07<00:06,  1.37s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:08<00:05,  1.36s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:09<00:04,  1.34s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:11<00:02,  1.34s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:12<00:01,  1.34s/it]\u001b[A\n","100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[Validating Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/140 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/140 [00:01<02:53,  1.25s/it]\u001b[A\n","  2%|▏         | 3/140 [00:01<00:49,  2.77it/s]\u001b[A\n","  4%|▎         | 5/140 [00:01<00:27,  4.92it/s]\u001b[A\n","  6%|▌         | 8/140 [00:01<00:16,  8.16it/s]\u001b[A\n","  7%|▋         | 10/140 [00:01<00:13,  9.64it/s]\u001b[A\n","  9%|▊         | 12/140 [00:01<00:11, 11.07it/s]\u001b[A\n"," 10%|█         | 14/140 [00:01<00:10, 12.53it/s]\u001b[A\n"," 12%|█▏        | 17/140 [00:02<00:07, 15.83it/s]\u001b[A\n"," 14%|█▍        | 20/140 [00:02<00:06, 18.81it/s]\u001b[A\n"," 16%|█▋        | 23/140 [00:02<00:05, 21.26it/s]\u001b[A\n"," 19%|█▊        | 26/140 [00:02<00:04, 23.14it/s]\u001b[A\n"," 21%|██        | 29/140 [00:02<00:04, 24.40it/s]\u001b[A\n"," 23%|██▎       | 32/140 [00:02<00:04, 25.85it/s]\u001b[A\n"," 25%|██▌       | 35/140 [00:02<00:04, 26.05it/s]\u001b[A\n"," 27%|██▋       | 38/140 [00:02<00:03, 26.72it/s]\u001b[A\n"," 29%|██▉       | 41/140 [00:02<00:03, 27.35it/s]\u001b[A\n"," 31%|███▏      | 44/140 [00:03<00:03, 27.41it/s]\u001b[A\n"," 34%|███▎      | 47/140 [00:03<00:03, 27.78it/s]\u001b[A\n"," 36%|███▌      | 50/140 [00:03<00:03, 28.20it/s]\u001b[A\n"," 38%|███▊      | 53/140 [00:03<00:03, 27.79it/s]\u001b[A\n"," 40%|████      | 56/140 [00:03<00:03, 27.85it/s]\u001b[A\n"," 42%|████▏     | 59/140 [00:03<00:02, 27.68it/s]\u001b[A\n"," 44%|████▍     | 62/140 [00:03<00:02, 27.27it/s]\u001b[A\n"," 46%|████▋     | 65/140 [00:03<00:02, 26.75it/s]\u001b[A\n"," 49%|████▊     | 68/140 [00:03<00:02, 26.72it/s]\u001b[A\n"," 51%|█████     | 71/140 [00:04<00:02, 27.17it/s]\u001b[A\n"," 53%|█████▎    | 74/140 [00:04<00:02, 27.02it/s]\u001b[A\n"," 55%|█████▌    | 77/140 [00:04<00:02, 26.94it/s]\u001b[A\n"," 57%|█████▋    | 80/140 [00:04<00:02, 27.19it/s]\u001b[A\n"," 59%|█████▉    | 83/140 [00:04<00:02, 26.84it/s]\u001b[A\n"," 61%|██████▏   | 86/140 [00:04<00:01, 27.19it/s]\u001b[A\n"," 64%|██████▎   | 89/140 [00:04<00:01, 27.35it/s]\u001b[A\n"," 66%|██████▌   | 92/140 [00:04<00:01, 26.52it/s]\u001b[A\n"," 68%|██████▊   | 95/140 [00:04<00:01, 27.07it/s]\u001b[A\n"," 70%|███████   | 98/140 [00:05<00:01, 27.25it/s]\u001b[A\n"," 72%|███████▏  | 101/140 [00:05<00:01, 27.63it/s]\u001b[A\n"," 75%|███████▌  | 105/140 [00:05<00:01, 28.76it/s]\u001b[A\n"," 77%|███████▋  | 108/140 [00:05<00:01, 28.52it/s]\u001b[A\n"," 79%|███████▉  | 111/140 [00:05<00:01, 28.71it/s]\u001b[A\n"," 81%|████████▏ | 114/140 [00:05<00:00, 28.92it/s]\u001b[A\n"," 84%|████████▎ | 117/140 [00:05<00:00, 28.45it/s]\u001b[A\n"," 86%|████████▌ | 120/140 [00:05<00:00, 27.91it/s]\u001b[A\n"," 88%|████████▊ | 123/140 [00:05<00:00, 28.49it/s]\u001b[A\n"," 90%|█████████ | 126/140 [00:06<00:00, 28.11it/s]\u001b[A\n"," 92%|█████████▏| 129/140 [00:06<00:00, 28.59it/s]\u001b[A\n"," 94%|█████████▍| 132/140 [00:06<00:00, 28.55it/s]\u001b[A\n"," 96%|█████████▋| 135/140 [00:06<00:00, 28.46it/s]\u001b[A\n","100%|██████████| 140/140 [00:06<00:00, 21.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch: [6/20]  train_loss: 0.0172  -  train_accuracy: 0.9942 -  val_loss: 2.7157  -  val_accuracy: 0.8357  -  val_correct: 117       \n","wrong predict : [('normal_7_aug12.pt',), ('normal_1_aug16.pt',), ('normal_1_aug10.pt',), ('normal_1_aug11.pt',), ('normal_1_aug18.pt',), ('normal_1_aug17.pt',), ('normal_7_aug7.pt',), ('normal_1_aug13.pt',), ('normal_1_aug3.pt',), ('normal_1_aug1.pt',), ('normal_1_aug6.pt',), ('normal_1_aug8.pt',), ('normal_1_aug15.pt',), ('normal_1_aug7.pt',), ('normal_1_aug20.pt',), ('normal_1_aug19.pt',), ('normal_1_aug2.pt',), ('normal_1_aug9.pt',), ('normal_1_aug12.pt',), ('normal_1_aug14.pt',), ('normal_1_aug5.pt',), ('normal_7_aug11.pt',), ('normal_1_aug4.pt',)]\n","Model saved\n","\t      Precision: 1.0000  -  Recall: 0.7125  -  F1 Score: 0.8321\n","epoch:7\n","result_path:/content/drive/My Drive/Deep_X_torch/result/result_2/train_2\n","Model loaded\n","[Training Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:01<00:15,  1.73s/it]\u001b[A\n"," 20%|██        | 2/10 [00:03<00:12,  1.50s/it]\u001b[A\n"," 30%|███       | 3/10 [00:04<00:09,  1.43s/it]\u001b[A\n"," 40%|████      | 4/10 [00:05<00:08,  1.39s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:07<00:06,  1.37s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:08<00:05,  1.36s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:09<00:04,  1.35s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:11<00:02,  1.35s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:12<00:01,  1.35s/it]\u001b[A\n","100%|██████████| 10/10 [00:13<00:00,  1.40s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[Validating Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/140 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/140 [00:00<00:41,  3.39it/s]\u001b[A\n","  3%|▎         | 4/140 [00:00<00:12, 11.31it/s]\u001b[A\n","  5%|▌         | 7/140 [00:00<00:07, 16.78it/s]\u001b[A\n","  7%|▋         | 10/140 [00:00<00:06, 20.43it/s]\u001b[A\n","  9%|▉         | 13/140 [00:00<00:05, 22.44it/s]\u001b[A\n"," 11%|█▏        | 16/140 [00:00<00:05, 24.48it/s]\u001b[A\n"," 14%|█▎        | 19/140 [00:00<00:04, 24.58it/s]\u001b[A\n"," 16%|█▌        | 22/140 [00:01<00:04, 25.73it/s]\u001b[A\n"," 18%|█▊        | 25/140 [00:01<00:04, 26.51it/s]\u001b[A\n"," 20%|██        | 28/140 [00:01<00:04, 26.81it/s]\u001b[A\n"," 22%|██▏       | 31/140 [00:01<00:04, 27.07it/s]\u001b[A\n"," 24%|██▍       | 34/140 [00:01<00:03, 27.45it/s]\u001b[A\n"," 26%|██▋       | 37/140 [00:01<00:03, 27.38it/s]\u001b[A\n"," 29%|██▊       | 40/140 [00:01<00:03, 27.54it/s]\u001b[A\n"," 31%|███       | 43/140 [00:01<00:03, 27.39it/s]\u001b[A\n"," 33%|███▎      | 46/140 [00:01<00:03, 26.96it/s]\u001b[A\n"," 35%|███▌      | 49/140 [00:02<00:03, 27.60it/s]\u001b[A\n"," 37%|███▋      | 52/140 [00:02<00:03, 27.31it/s]\u001b[A\n"," 39%|███▉      | 55/140 [00:02<00:03, 27.37it/s]\u001b[A\n"," 41%|████▏     | 58/140 [00:02<00:02, 27.49it/s]\u001b[A\n"," 44%|████▎     | 61/140 [00:02<00:02, 27.79it/s]\u001b[A\n"," 46%|████▌     | 64/140 [00:02<00:02, 28.21it/s]\u001b[A\n"," 48%|████▊     | 67/140 [00:02<00:02, 27.95it/s]\u001b[A\n"," 50%|█████     | 70/140 [00:02<00:02, 28.37it/s]\u001b[A\n"," 52%|█████▏    | 73/140 [00:02<00:02, 28.07it/s]\u001b[A\n"," 54%|█████▍    | 76/140 [00:03<00:02, 26.88it/s]\u001b[A\n"," 56%|█████▋    | 79/140 [00:03<00:02, 27.19it/s]\u001b[A\n"," 59%|█████▊    | 82/140 [00:03<00:02, 27.34it/s]\u001b[A\n"," 61%|██████    | 85/140 [00:03<00:01, 27.82it/s]\u001b[A\n"," 63%|██████▎   | 88/140 [00:03<00:01, 27.78it/s]\u001b[A\n"," 65%|██████▌   | 91/140 [00:03<00:01, 27.55it/s]\u001b[A\n"," 67%|██████▋   | 94/140 [00:03<00:01, 27.32it/s]\u001b[A\n"," 69%|██████▉   | 97/140 [00:03<00:01, 26.81it/s]\u001b[A\n"," 71%|███████▏  | 100/140 [00:03<00:01, 25.83it/s]\u001b[A\n"," 74%|███████▎  | 103/140 [00:04<00:01, 21.32it/s]\u001b[A\n"," 76%|███████▌  | 106/140 [00:04<00:01, 20.25it/s]\u001b[A\n"," 78%|███████▊  | 109/140 [00:04<00:01, 17.59it/s]\u001b[A\n"," 79%|███████▉  | 111/140 [00:04<00:01, 17.07it/s]\u001b[A\n"," 81%|████████  | 113/140 [00:04<00:01, 17.43it/s]\u001b[A\n"," 82%|████████▏ | 115/140 [00:04<00:01, 17.81it/s]\u001b[A\n"," 84%|████████▍ | 118/140 [00:04<00:01, 18.60it/s]\u001b[A\n"," 86%|████████▌ | 120/140 [00:05<00:01, 18.41it/s]\u001b[A\n"," 88%|████████▊ | 123/140 [00:05<00:00, 19.34it/s]\u001b[A\n"," 90%|█████████ | 126/140 [00:05<00:00, 19.92it/s]\u001b[A\n"," 91%|█████████▏| 128/140 [00:05<00:00, 19.93it/s]\u001b[A\n"," 93%|█████████▎| 130/140 [00:05<00:00, 19.36it/s]\u001b[A\n"," 95%|█████████▌| 133/140 [00:05<00:00, 19.85it/s]\u001b[A\n"," 96%|█████████▋| 135/140 [00:05<00:00, 19.68it/s]\u001b[A\n","100%|██████████| 140/140 [00:06<00:00, 22.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch: [7/20]  train_loss: 0.0053  -  train_accuracy: 1.0000 -  val_loss: 1.2432  -  val_accuracy: 0.8429  -  val_correct: 118       \n","wrong predict : [('normal_7_aug7.pt',), ('normal_1_aug13.pt',), ('normal_1_aug3.pt',), ('normal_1_aug7.pt',), ('normal_1_aug19.pt',), ('normal_1_aug16.pt',), ('normal_1_aug8.pt',), ('normal_1_aug6.pt',), ('normal_1_aug12.pt',), ('normal_1_aug18.pt',), ('normal_7_aug12.pt',), ('normal_1_aug4.pt',), ('normal_1_aug1.pt',), ('normal_1_aug11.pt',), ('normal_1_aug2.pt',), ('normal_1_aug5.pt',), ('normal_1_aug15.pt',), ('normal_1_aug10.pt',), ('normal_1_aug17.pt',), ('normal_1_aug20.pt',), ('normal_1_aug9.pt',), ('normal_1_aug14.pt',)]\n","Model saved\n","\t      Precision: 1.0000  -  Recall: 0.7250  -  F1 Score: 0.8406\n","epoch:8\n","result_path:/content/drive/My Drive/Deep_X_torch/result/result_2/train_2\n","Model loaded\n","[Training Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:01<00:15,  1.71s/it]\u001b[A\n"," 20%|██        | 2/10 [00:03<00:11,  1.50s/it]\u001b[A\n"," 30%|███       | 3/10 [00:04<00:09,  1.42s/it]\u001b[A\n"," 40%|████      | 4/10 [00:05<00:08,  1.39s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:07<00:06,  1.37s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:08<00:05,  1.36s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:09<00:04,  1.35s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:11<00:02,  1.35s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:12<00:01,  1.35s/it]\u001b[A\n","100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[Validating Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/140 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/140 [00:00<00:59,  2.34it/s]\u001b[A\n","  2%|▏         | 3/140 [00:00<00:21,  6.30it/s]\u001b[A\n","  4%|▍         | 6/140 [00:00<00:11, 11.45it/s]\u001b[A\n","  6%|▋         | 9/140 [00:00<00:08, 15.83it/s]\u001b[A\n","  9%|▊         | 12/140 [00:00<00:06, 19.33it/s]\u001b[A\n"," 11%|█         | 15/140 [00:01<00:05, 21.44it/s]\u001b[A\n"," 13%|█▎        | 18/140 [00:01<00:05, 23.30it/s]\u001b[A\n"," 15%|█▌        | 21/140 [00:01<00:04, 25.04it/s]\u001b[A\n"," 17%|█▋        | 24/140 [00:01<00:04, 25.73it/s]\u001b[A\n"," 19%|█▉        | 27/140 [00:01<00:04, 26.78it/s]\u001b[A\n"," 21%|██▏       | 30/140 [00:01<00:04, 27.02it/s]\u001b[A\n"," 24%|██▎       | 33/140 [00:01<00:03, 27.11it/s]\u001b[A\n"," 26%|██▌       | 36/140 [00:01<00:03, 27.55it/s]\u001b[A\n"," 28%|██▊       | 39/140 [00:01<00:03, 27.70it/s]\u001b[A\n"," 30%|███       | 42/140 [00:01<00:03, 27.94it/s]\u001b[A\n"," 32%|███▏      | 45/140 [00:02<00:03, 27.56it/s]\u001b[A\n"," 34%|███▍      | 48/140 [00:02<00:03, 27.85it/s]\u001b[A\n"," 36%|███▋      | 51/140 [00:02<00:03, 27.72it/s]\u001b[A\n"," 39%|███▊      | 54/140 [00:02<00:03, 28.11it/s]\u001b[A\n"," 41%|████      | 57/140 [00:02<00:02, 27.99it/s]\u001b[A\n"," 43%|████▎     | 60/140 [00:02<00:02, 28.41it/s]\u001b[A\n"," 45%|████▌     | 63/140 [00:02<00:02, 28.60it/s]\u001b[A\n"," 47%|████▋     | 66/140 [00:02<00:02, 28.56it/s]\u001b[A\n"," 49%|████▉     | 69/140 [00:02<00:02, 28.74it/s]\u001b[A\n"," 51%|█████▏    | 72/140 [00:03<00:02, 28.13it/s]\u001b[A\n"," 54%|█████▎    | 75/140 [00:03<00:02, 27.99it/s]\u001b[A\n"," 56%|█████▌    | 78/140 [00:03<00:02, 28.55it/s]\u001b[A\n"," 58%|█████▊    | 81/140 [00:03<00:02, 28.62it/s]\u001b[A\n"," 60%|██████    | 84/140 [00:03<00:01, 28.20it/s]\u001b[A\n"," 62%|██████▏   | 87/140 [00:03<00:01, 28.51it/s]\u001b[A\n"," 64%|██████▍   | 90/140 [00:03<00:01, 28.30it/s]\u001b[A\n"," 66%|██████▋   | 93/140 [00:03<00:01, 28.44it/s]\u001b[A\n"," 69%|██████▊   | 96/140 [00:03<00:01, 28.75it/s]\u001b[A\n"," 71%|███████   | 99/140 [00:03<00:01, 28.57it/s]\u001b[A\n"," 73%|███████▎  | 102/140 [00:04<00:01, 28.23it/s]\u001b[A\n"," 75%|███████▌  | 105/140 [00:04<00:01, 27.95it/s]\u001b[A\n"," 77%|███████▋  | 108/140 [00:04<00:01, 22.75it/s]\u001b[A\n"," 79%|███████▉  | 111/140 [00:04<00:01, 23.43it/s]\u001b[A\n"," 81%|████████▏ | 114/140 [00:04<00:01, 25.03it/s]\u001b[A\n"," 84%|████████▍ | 118/140 [00:04<00:00, 26.98it/s]\u001b[A\n"," 86%|████████▋ | 121/140 [00:04<00:00, 27.69it/s]\u001b[A\n"," 89%|████████▊ | 124/140 [00:04<00:00, 28.12it/s]\u001b[A\n"," 91%|█████████ | 127/140 [00:05<00:00, 28.62it/s]\u001b[A\n"," 93%|█████████▎| 130/140 [00:05<00:00, 26.94it/s]\u001b[A\n"," 95%|█████████▌| 133/140 [00:05<00:00, 27.56it/s]\u001b[A\n"," 97%|█████████▋| 136/140 [00:05<00:00, 27.25it/s]\u001b[A\n","100%|██████████| 140/140 [00:05<00:00, 24.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch: [8/20]  train_loss: 0.0051  -  train_accuracy: 0.9981 -  val_loss: 1.0025  -  val_accuracy: 0.8357  -  val_correct: 117       \n","wrong predict : [('normal_1_aug11.pt',), ('normal_7_aug12.pt',), ('normal_5_aug10.pt',), ('normal_1_aug9.pt',), ('normal_7_aug7.pt',), ('normal_1_aug2.pt',), ('normal_1_aug18.pt',), ('normal_1_aug15.pt',), ('normal_1_aug4.pt',), ('normal_1_aug14.pt',), ('normal_1_aug8.pt',), ('normal_1_aug20.pt',), ('normal_1_aug17.pt',), ('normal_1_aug7.pt',), ('normal_1_aug13.pt',), ('normal_1_aug10.pt',), ('normal_1_aug19.pt',), ('normal_1_aug12.pt',), ('normal_1_aug1.pt',), ('normal_1_aug3.pt',), ('normal_1_aug5.pt',), ('normal_1_aug6.pt',), ('normal_1_aug16.pt',)]\n","Model saved\n","\t      Precision: 1.0000  -  Recall: 0.7125  -  F1 Score: 0.8321\n","epoch:9\n","result_path:/content/drive/My Drive/Deep_X_torch/result/result_2/train_2\n","Model loaded\n","[Training Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:02<00:19,  2.22s/it]\u001b[A\n"," 20%|██        | 2/10 [00:03<00:13,  1.71s/it]\u001b[A\n"," 30%|███       | 3/10 [00:04<00:10,  1.54s/it]\u001b[A\n"," 40%|████      | 4/10 [00:06<00:08,  1.46s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:07<00:07,  1.42s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:08<00:05,  1.39s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:10<00:04,  1.38s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:11<00:02,  1.37s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:12<00:01,  1.36s/it]\u001b[A\n","100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n"]},{"output_type":"stream","name":"stdout","text":["[Validating Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/140 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/140 [00:00<00:42,  3.30it/s]\u001b[A\n","  3%|▎         | 4/140 [00:00<00:12, 10.98it/s]\u001b[A\n","  5%|▌         | 7/140 [00:00<00:08, 16.53it/s]\u001b[A\n","  7%|▋         | 10/140 [00:00<00:06, 20.09it/s]\u001b[A\n","  9%|▉         | 13/140 [00:00<00:05, 22.12it/s]\u001b[A\n"," 11%|█▏        | 16/140 [00:00<00:05, 24.27it/s]\u001b[A\n"," 14%|█▎        | 19/140 [00:00<00:04, 25.15it/s]\u001b[A\n"," 16%|█▌        | 22/140 [00:01<00:04, 26.05it/s]\u001b[A\n"," 19%|█▊        | 26/140 [00:01<00:04, 27.51it/s]\u001b[A\n"," 21%|██        | 29/140 [00:01<00:04, 27.55it/s]\u001b[A\n"," 23%|██▎       | 32/140 [00:01<00:04, 26.97it/s]\u001b[A\n"," 25%|██▌       | 35/140 [00:01<00:03, 26.74it/s]\u001b[A\n"," 27%|██▋       | 38/140 [00:01<00:03, 27.13it/s]\u001b[A\n"," 29%|██▉       | 41/140 [00:01<00:03, 26.70it/s]\u001b[A\n"," 31%|███▏      | 44/140 [00:01<00:03, 27.20it/s]\u001b[A\n"," 34%|███▎      | 47/140 [00:01<00:03, 27.80it/s]\u001b[A\n"," 36%|███▌      | 50/140 [00:02<00:03, 27.93it/s]\u001b[A\n"," 38%|███▊      | 53/140 [00:02<00:03, 27.87it/s]\u001b[A\n"," 40%|████      | 56/140 [00:02<00:02, 28.09it/s]\u001b[A\n"," 42%|████▏     | 59/140 [00:02<00:02, 28.56it/s]\u001b[A\n"," 44%|████▍     | 62/140 [00:02<00:02, 28.39it/s]\u001b[A\n"," 46%|████▋     | 65/140 [00:02<00:02, 28.17it/s]\u001b[A\n"," 49%|████▉     | 69/140 [00:02<00:02, 28.77it/s]\u001b[A\n"," 51%|█████▏    | 72/140 [00:02<00:02, 28.25it/s]\u001b[A\n"," 54%|█████▍    | 76/140 [00:02<00:02, 29.18it/s]\u001b[A\n"," 56%|█████▋    | 79/140 [00:03<00:02, 28.86it/s]\u001b[A\n"," 59%|█████▊    | 82/140 [00:03<00:02, 28.70it/s]\u001b[A\n"," 61%|██████    | 85/140 [00:03<00:01, 28.39it/s]\u001b[A\n"," 63%|██████▎   | 88/140 [00:03<00:01, 28.26it/s]\u001b[A\n"," 65%|██████▌   | 91/140 [00:03<00:01, 25.80it/s]\u001b[A\n"," 67%|██████▋   | 94/140 [00:03<00:01, 23.81it/s]\u001b[A\n"," 69%|██████▉   | 97/140 [00:03<00:01, 22.41it/s]\u001b[A\n"," 71%|███████▏  | 100/140 [00:04<00:01, 21.98it/s]\u001b[A\n"," 74%|███████▎  | 103/140 [00:04<00:01, 21.26it/s]\u001b[A\n"," 76%|███████▌  | 106/140 [00:04<00:01, 21.03it/s]\u001b[A\n"," 78%|███████▊  | 109/140 [00:04<00:01, 21.04it/s]\u001b[A\n"," 80%|████████  | 112/140 [00:04<00:01, 21.07it/s]\u001b[A\n"," 82%|████████▏ | 115/140 [00:04<00:01, 21.21it/s]\u001b[A\n"," 84%|████████▍ | 118/140 [00:04<00:01, 20.94it/s]\u001b[A\n"," 86%|████████▋ | 121/140 [00:05<00:00, 20.42it/s]\u001b[A\n"," 89%|████████▊ | 124/140 [00:05<00:00, 18.58it/s]\u001b[A\n"," 90%|█████████ | 126/140 [00:05<00:00, 16.67it/s]\u001b[A\n"," 91%|█████████▏| 128/140 [00:05<00:00, 15.54it/s]\u001b[A\n"," 93%|█████████▎| 130/140 [00:05<00:00, 15.60it/s]\u001b[A\n"," 94%|█████████▍| 132/140 [00:05<00:00, 16.13it/s]\u001b[A\n"," 96%|█████████▌| 134/140 [00:05<00:00, 16.57it/s]\u001b[A\n"," 97%|█████████▋| 136/140 [00:05<00:00, 17.21it/s]\u001b[A\n"," 99%|█████████▊| 138/140 [00:06<00:00, 17.42it/s]\u001b[A\n","100%|██████████| 140/140 [00:06<00:00, 21.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch: [9/20]  train_loss: 0.0011  -  train_accuracy: 1.0000 -  val_loss: 1.0004  -  val_accuracy: 0.8286  -  val_correct: 116       \n","wrong predict : [('normal_1_aug3.pt',), ('normal_1_aug4.pt',), ('normal_1_aug8.pt',), ('normal_1_aug19.pt',), ('normal_7_aug12.pt',), ('normal_1_aug2.pt',), ('normal_1_aug18.pt',), ('normal_1_aug15.pt',), ('normal_5_aug10.pt',), ('normal_1_aug5.pt',), ('normal_1_aug9.pt',), ('normal_1_aug13.pt',), ('normal_7_aug19.pt',), ('normal_1_aug12.pt',), ('normal_7_aug7.pt',), ('normal_1_aug11.pt',), ('normal_1_aug20.pt',), ('normal_1_aug1.pt',), ('normal_1_aug6.pt',), ('normal_1_aug7.pt',), ('normal_1_aug16.pt',), ('normal_1_aug17.pt',), ('normal_1_aug10.pt',), ('normal_1_aug14.pt',)]\n","Model saved\n","\t      Precision: 1.0000  -  Recall: 0.7000  -  F1 Score: 0.8235\n","epoch:10\n","result_path:/content/drive/My Drive/Deep_X_torch/result/result_2/train_2\n","Model loaded\n","[Training Progress]: \n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n"," 10%|█         | 1/10 [00:01<00:15,  1.75s/it]\u001b[A\n"," 20%|██        | 2/10 [00:03<00:12,  1.52s/it]\u001b[A\n"," 30%|███       | 3/10 [00:04<00:10,  1.44s/it]\u001b[A\n"," 40%|████      | 4/10 [00:05<00:08,  1.40s/it]\u001b[A\n"," 50%|█████     | 5/10 [00:07<00:06,  1.38s/it]\u001b[A\n"," 60%|██████    | 6/10 [00:08<00:05,  1.37s/it]\u001b[A\n"," 70%|███████   | 7/10 [00:09<00:04,  1.36s/it]\u001b[A\n"," 80%|████████  | 8/10 [00:11<00:02,  1.36s/it]\u001b[A\n"," 90%|█████████ | 9/10 [00:14<00:01,  1.58s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-b1121655c7bc>\u001b[0m in \u001b[0;36m<cell line: 456>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0mresult_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/Deep_X_torch/result'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_data_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mabnormal_data_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_normal_tensor_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_abnormal_tensor_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-b1121655c7bc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(normal_data_dir, abnormal_data_dir, train_normal_tensor_path, train_abnormal_tensor_path, result_path, num_fold)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_correct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn as nn\n","import os\n","import numpy as np\n","import torch.optim as optim\n","import torchvision.models as models\n","import matplotlib.pyplot as plt\n","import csv\n","import random\n","import timm\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import ConcatDataset\n","from sklearn import datasets\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime\n","\n","class MyDataset(Dataset):\n","    def __init__(self, data_path):\n","        self.data_path = data_path\n","        self.class_to_idx = {'abnormal': 1, 'normal': 0}  # 定義類別名稱到類別索引的映射\n","        self.data = []\n","        self.filenames = []  # store filenames\n","        for filename in os.listdir(data_path):\n","            if filename.endswith('.pt'):\n","                tensor = torch.load(os.path.join(data_path, filename))\n","                if filename.split('_')[0] == 'normal':\n","                    label_idx = 0\n","                else:\n","                    label_idx = 1\n","                self.data.append((tensor, label_idx, filename))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        tensor, labels, filename = self.data[index]\n","        return tensor, labels, filename\n","\n","class CombinedDataset(ConcatDataset):\n","    def __init__(self, dataset1, dataset2):\n","        super().__init__([dataset1, dataset2])\n","\n","    def __getitem__(self, index):\n","        return super().__getitem__(index)\n","\n","    def __len__(self):\n","        return super().__len__()\n","\n","\n","# 建立資料夾顯示訓練結果\n","def mkdir_outcome(result_path):\n","    file_names = os.listdir(result_path)\n","    num_max = 0\n","    for file_name in file_names:\n","        if file_name.startswith(\"result_\"):\n","            num_str = file_name.split(\"_\")[1]\n","            num = int(num_str)\n","            if(num > num_max):\n","                num_max = num\n","    # make folder for train result\n","    result_path = os.path.join(result_path,\"result_{}\".format(num_max + 1))\n","    result_path_train = os.path.join(result_path,\"train_{}\".format(num_max + 1))\n","    os.makedirs(result_path,exist_ok=True)\n","    os.makedirs(result_path_train,exist_ok=True)\n","    return result_path_train\n","\n","\n","# 模型評估指標\n","def validation_index(conf_matrix):\n","    # Confusion Matrix to calculate [accuracy,precision,recall]\n","    precision = 0.0\n","    recall = 0.0\n","    f1_score = 0.0\n","    if((conf_matrix[0][0] + conf_matrix[0][1]) != 0):\n","        precision = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[0][1])\n","    if((conf_matrix[0][0] + conf_matrix[1][0]) != 0):\n","        recall = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[1][0])\n","    if((precision + recall) != 0):\n","        f1_score = 2*precision*recall / (precision + recall)\n","    TPR = recall\n","    FPR = conf_matrix[0][1] / (conf_matrix[0][1] + conf_matrix[1][1])\n","    print(\"\\t      Precision: {:<.4f}  -  Recall: {:<.4f}  -  F1 Score: {:<.4f}\".format(precision,recall,f1_score))\n","    return precision,recall,f1_score,TPR,FPR\n","\n","\n","# 混淆矩陣\n","def Confusion_Matrix(result_path,conf_matrix,fold_nums):\n","    # Create the 'confusion_matrix_record' directory if it doesn't exist\n","    confusion_matrix_record_dir = os.path.join(result_path, 'confusion_matrix_record')\n","    plt.clf()\n","    if not os.path.exists(confusion_matrix_record_dir):\n","        os.makedirs(confusion_matrix_record_dir)\n","\n","    confusion_matrix = np.array([[conf_matrix[0][0], conf_matrix[0][1]], [conf_matrix[1][0], conf_matrix[1][1]]])\n","    print(\"Confusion matrix:\")\n","    print(conf_matrix)\n","    plt.imshow(confusion_matrix, cmap=plt.cm.Blues, interpolation='nearest')\n","    plt.colorbar()\n","\n","    # confusion matrix index 各個 index 的數值\n","    for i in range(2):\n","        for j in range(2):\n","            text_color = 'black' if confusion_matrix[i][j] < 0.5 * confusion_matrix.max() else 'white'\n","            plt.annotate(str(confusion_matrix[i][j]), xy=(j, i), ha='center', va='center', color=text_color)\n","    tick_marks = np.arange(2)\n","    plt.xticks(tick_marks, ['Positive', 'Negative'])\n","    plt.yticks(tick_marks, ['Positive', 'Negative'])\n","    plt.ylabel('Predicted Label')\n","    plt.xlabel('True Label')\n","    plt.title('Confusion Matrix')\n","    result_path = result_path + '/confusion_matrix_record'\n","    plt.savefig(os.path.join(result_path,'confusion_matrix_fold'+str(fold_nums + 1)+'.png'))\n","\n","\n","# ROC曲線\n","def ROC_Curve(result_path,tpr_list,fpr_list,fold_nums):\n","    # Create the 'roc_curve_record' directory if it doesn't exist\n","    roc_curve_record_dir = os.path.join(result_path, 'roc_curve_record')\n","    if not os.path.exists(roc_curve_record_dir):\n","        os.makedirs(roc_curve_record_dir)\n","\n","    # 計算 AUC\n","    roc_auc = np.trapz(tpr_list, fpr_list)\n","\n","    # 繪製 ROC 曲線\n","    plt.clf()\n","    plt.plot(fpr_list, tpr_list, lw=1, label='ROC (AUC = %0.2f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], '--', color='gray', label='Random Guessing')\n","    plt.xlim([-0.05, 1.05])\n","    plt.ylim([-0.05, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend()\n","    result_path = result_path + '/roc_curve_record'\n","    plt.savefig(os.path.join(result_path,'Roc_curve'+str(fold_nums + 1)+'.png'))\n","\n","\n","# 輸出每一次 epoch 的結果\n","def CSV_Output(result_path,parameter,num_epochs,train_loss_list,train_acc_list,val_loss_list,val_acc_list,precision_list,recall_list,TPR_list,FPR_list,f1_score_list,fold_wrong_predict,fold_nums):\n","    # Create the 'csv_record' directory if it doesn't exist\n","    csv_record_dir = os.path.join(result_path, 'csv_record')\n","    if not os.path.exists(csv_record_dir):\n","        os.makedirs(csv_record_dir)\n","    with open(result_path + '/csv_record/epoch_fold'+str(fold_nums + 1)+'.csv','w',newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['num_epochs','batch_size','learning_rate','num_classes','device','start_time','end_time','num_fold'])\n","        writer.writerow(parameter)\n","        writer.writerow('')\n","        writer.writerow(['Epoch','train_loss','train_acc','val_loss','val_acc','precision','recall','TPR','FPR','F1 score'])\n","        for epoch in range(num_epochs):\n","            writer.writerow([epoch + 1,\n","                            round(train_loss_list[epoch], 4),\n","                            round(train_acc_list[epoch].item(), 4),\n","                            round(val_loss_list[epoch], 4),\n","                            round(val_acc_list[epoch].item(), 4),\n","                            round(precision_list[epoch], 4),\n","                            round(recall_list[epoch], 4),\n","                            round(TPR_list[epoch], 4),\n","                            round(FPR_list[epoch], 4),\n","                            round(f1_score_list[epoch], 4)])\n","        writer.writerow([f'wrong_predict:',fold_wrong_predict])\n","    print('CSV output Sucessfully')\n","\n","def print_filename_in_txt(train_loader, valid_loader, result_path, fold_num):\n","    # Initialize empty lists to store filenames\n","    train_filenames = []\n","    valid_filenames = []\n","\n","    # Iterate over the training dataset\n","    for batch_idx, (data, target, filename) in enumerate(train_loader):\n","        # Append the filename to the list\n","        train_filenames.extend(filename)\n","\n","    # Iterate over the validation dataset\n","    for batch_idx, (data, target, filename) in enumerate(valid_loader):\n","        # Append the filename to the list\n","        valid_filenames.extend(filename)\n","\n","    # Create the 'file_name_record' directory if it doesn't exist\n","    file_record_dir = os.path.join(result_path, 'file_name_record')\n","    if not os.path.exists(file_record_dir):\n","        os.makedirs(file_record_dir)\n","\n","    # Save the training filenames as a text file\n","    with open(result_path + '/file_name_record/train_filenames_fold_'+str(fold_num + 1)+'.txt', 'w') as file:\n","        for filename in train_filenames:\n","            file.write(filename + '\\n')\n","\n","    # Save the validation filenames as a text file\n","    with open(result_path + '/file_name_record/valid_filenames_fold_'+str(fold_num + 1)+'.txt', 'w') as file:\n","        for filename in valid_filenames:\n","            file.write(filename + '\\n')\n","\n","    print(f\"Filenames saved in {result_path}/train_filenames.txt and {result_path}/valid_filenames.txt\")\n","\n","def calculate_average(avg_train_acc_list, avg_val_acc_list, avg_recall_list, avg_precision_list, avg_f1_score_list, avg_TPR_list, avg_FPR_list, fold_nums, result_path):\n","    # Calculate averages\n","    avg_train_acc = sum(avg_train_acc_list) / fold_nums\n","    avg_val_acc = sum(avg_val_acc_list) / fold_nums\n","    avg_recall = sum(avg_recall_list) / fold_nums\n","    avg_precision = sum(avg_precision_list) / fold_nums\n","    avg_f1_score = sum(avg_f1_score_list) / fold_nums\n","    avg_TPR = sum(avg_TPR_list) / fold_nums\n","    avg_FPR = sum(avg_FPR_list) / fold_nums\n","\n","    # Save averages to a text file\n","    with open(result_path + '/Average.txt', 'w') as file:\n","        file.write(f\"Avg Train Accuracy: {avg_train_acc}\\n\")\n","        file.write(f\"Avg Validation Accuracy: {avg_val_acc}\\n\")\n","        file.write(f\"Avg Recall: {avg_recall}\\n\")\n","        file.write(f\"Avg Precision: {avg_precision}\\n\")\n","        file.write(f\"Avg F1 Score: {avg_f1_score}\\n\")\n","        file.write(f\"Avg TPR: {avg_TPR}\\n\")\n","        file.write(f\"Avg FPR: {avg_FPR}\\n\")\n","\n","    print(f\"Averages saved to {result_path}\")\n","\n","def train(normal_data_dir,abnormal_data_dir,train_normal_tensor_path,train_abnormal_tensor_path,result_path,num_fold):\n","    #超參數設定\n","    batch_size = 52\n","    learning_rate = 0.001\n","    num_epochs = 20\n","    num_classes = 2\n","    num_folds = num_fold\n","    start_time = datetime.now()\n","    end_time = 0\n","    num_argumentation = 20\n","    conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n","\n","    # Get the dataset\n","    train_normal_dataset = MyDataset(train_normal_tensor_path)\n","    train_abnormal_dataset = MyDataset(train_abnormal_tensor_path)\n","    # Combine the datasets\n","    train_datasets = CombinedDataset(train_normal_dataset,train_abnormal_dataset)\n","\n","    # Create the k-fold cross-validation object\n","    kfold = KFold(n_splits=num_folds)\n","\n","    #印出資料集大小\n","    print(\"train dataset's size : \" + str(len(train_datasets)))\n","\n","    #創建模型\n","    # model = models.resnet152(pretrained=True)\n","    model = timm.create_model('seresnet152d', pretrained=True)\n","    model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    #print(model)\n","    #print(model.fc)\n","\n","    #將模型移動到GPU上進行運算\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    model.fc.to(device)\n","    print(\"Device used : \" + str(device))\n","\n","    # make dir to save the training outcome\n","    result_path = mkdir_outcome(result_path)\n","\n","    avg_train_acc_list = []\n","    avg_val_acc_list = []\n","    avg_recall_list = []\n","    avg_precision_list = []\n","    avg_f1_score_list = []\n","    avg_TPR_list = []\n","    avg_FPR_list = []\n","\n","    files = []\n","    file_names = os.listdir(normal_data_dir)\n","    for file_name in file_names:\n","        name = os.path.splitext(file_name)[0]\n","        files.append(name)\n","\n","    file_names = os.listdir(abnormal_data_dir)\n","    for file_name in file_names:\n","        name = os.path.splitext(file_name)[0]\n","        files.append(name)\n","\n","    random.shuffle(files)\n","\n","    for fold, (train_indices, valid_indices) in enumerate(kfold.split(files)):\n","        print(f\"Fold: {fold+1}\")\n","\n","        #定義損失函數和優化器\n","        m = nn.Sigmoid()\n","        criterion = nn.BCELoss()\n","        # criterion = nn.CrossEntropyLoss()\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","        train_loss_list = []\n","        train_acc_list = []\n","        val_loss_list = []\n","        val_acc_list = []\n","        recall_list = []\n","        precision_list = []\n","        f1_score_list = []\n","        TPR_list = []\n","        FPR_list = []\n","        fold_wrong_predict = []\n","\n","        train_files = [files[i] for i in train_indices]\n","        valid_files = [files[i] for i in valid_indices]\n","\n","        # 定义用于存储训练集和验证集的文件名的列表\n","        train_data_files = []\n","        valid_data_files = []\n","\n","        # 遍历训练集文件名，根据增强数据的命名规则，找到对应的增强文件名\n","        for file in train_files:\n","            labels, index = file.split('_')\n","            # 构造增强后数据的文件名\n","            for num in range(1,num_argumentation + 1):\n","              augmented_file = f\"{labels}_{index}_aug{num}.pt\"\n","              # 将增强后数据的文件名添加到训练集文件名列表\n","              train_data_files.append(augmented_file)\n","\n","        # 遍历验证集文件名，根据增强数据的命名规则，找到对应的增强文件名\n","        for file in valid_files:\n","            labels, index = file.split('_')\n","            # 构造增强后数据的文件名\n","            for num in range(1,num_argumentation + 1):\n","              augmented_file = f\"{labels}_{index}_aug{num}.pt\"\n","              valid_data_files.append(augmented_file)\n","\n","        train = []\n","        valid = []\n","\n","        # 遍历combined_dataset中的样本索引\n","        for index, (data, labels, filename) in enumerate(train_datasets):\n","            # 检查当前样本的文件名是否在训练集文件名列表中\n","            if filename in train_data_files:\n","                train.append(index)\n","            # 检查当前样本的文件名是否在验证集文件名列表中\n","            elif filename in valid_data_files:\n","                valid.append(index)\n","\n","        # Create the train and validation datasets for this fold\n","        train_dataset = torch.utils.data.Subset(train_datasets, train)\n","        valid_dataset = torch.utils.data.Subset(train_datasets, valid)\n","\n","\n","        print(\"train_dataset : \" + str(len(train_dataset)),\",valid_dataset : \" + str(len(valid_dataset)))\n","\n","        # Create the data loaders for this fold\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","        valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=True, num_workers=4)\n","        print_filename_in_txt(train_loader,valid_loader,result_path,fold)\n","\n","        #訓練模型\n","        for epoch in range(num_epochs):\n","            print(\"epoch:\"+f\"{epoch+1}\")\n","            train_loss = 0\n","            train_correct = 0\n","            train_acc = 0\n","            val_loss = 0\n","            val_corrects = 0\n","            val_acc = 0\n","\n","            print(\"result_path:\" + str(result_path))\n","\n","            if(epoch+1 > 1) :\n","              model.load_state_dict(torch.load(os.path.join(result_path,\"train\"+f'_fold_{fold+1}'+\".pt\")))\n","              print(\"Model loaded\")\n","\n","\n","            #初始化\n","            conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n","\n","            print(\"[Training Progress]: \")\n","            model.train()\n","            for inputs, labels, filename in tqdm(train_loader):\n","                targets=torch.eye(2)[labels.long(), :]\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                targets = targets.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                loss = criterion(m(outputs),targets.float())\n","                _, preds = torch.max(outputs, 1)\n","                train_correct += torch.sum(preds == labels.data)\n","                loss.backward()\n","                optimizer.step()\n","                train_loss += loss.item() * inputs.size(0)\n","            train_loss = train_loss / len(train_loader.dataset)\n","            train_acc = train_correct.double() / len(train_loader.dataset)\n","            train_loss_list.append(train_loss)\n","\n","            model.eval()\n","\n","            print(\"[Validating Progress]: \")\n","            wrong_predict = []\n","            for inputs, labels, filename in tqdm(valid_loader):\n","                targets=torch.eye(2)[labels.long(), :]\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                targets = targets.to(device)\n","                with torch.set_grad_enabled(False):\n","                    outputs = model(inputs)\n","                    loss = criterion(m(outputs),targets.float())\n","                val_loss += loss.item() * inputs.size(0)\n","                _, preds = torch.max(outputs, 1)\n","                val_corrects += torch.sum(preds == labels.data)\n","\n","                # Count Confusion Matrix\n","                for t, p in zip(preds.view(-1), labels.view(-1)):\n","                    conf_matrix[t.long(), p.long()] += 1\n","                    if t != p:\n","                      wrong_predict.append(filename)\n","            val_loss = val_loss / len(valid_loader.dataset)\n","            val_acc = val_corrects.double() / len(valid_loader.dataset)\n","            val_loss_list.append(val_loss)\n","\n","            scheduler.step()\n","            end_time = datetime.now()\n","            print('\\nEpoch: [{}/{}]  train_loss: {:<.4f}  -  train_accuracy: {:<.4f} -  val_loss: {:<.4f}  -  val_accuracy: {:<.4f}  -  val_correct: {:<10}'.format(\n","                epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc, val_corrects))\n","            print('wrong predict : ' + str(wrong_predict))\n","            torch.save(model.state_dict(),os.path.join(result_path,\"train\"+f'_fold_{fold+1}'+\".pt\"))\n","            print(\"Model saved\")\n","\n","            # validation index (評估指標)\n","            precision,recall,f1_score,TPR,FPR = validation_index(conf_matrix)\n","\n","            # record the outcomes\n","            val_acc_list.append(val_acc),train_acc_list.append(train_acc),precision_list.append(precision),recall_list.append(recall)\n","            f1_score_list.append(f1_score),TPR_list.append(TPR),FPR_list.append(FPR)\n","\n","            if epoch + 1 == num_epochs:\n","              torch.cuda.empty_cache()\n","              avg_train_acc_list.append(train_acc),avg_val_acc_list.append(val_acc),avg_recall_list.append(recall),avg_precision_list.append(precision),avg_f1_score_list.append(f1_score),avg_TPR_list.append(TPR),avg_FPR_list.append(FPR),fold_wrong_predict.append(wrong_predict)\n","\n","        # function of confusion matrix param(folder path, matrix, test normal dataset length, test unnormal dataset length)\n","        Confusion_Matrix(result_path,conf_matrix,fold)\n","        # functioN to show ROC curve\n","        ROC_Curve(result_path,TPR_list,FPR_list,fold)\n","        # CSV visualization\n","        param = [num_epochs,batch_size,learning_rate,num_classes,device,start_time,end_time,fold]\n","        CSV_Output(result_path,param,num_epochs,train_loss_list,train_acc_list,val_loss_list,val_acc_list,precision_list,recall_list,TPR_list,FPR_list,f1_score_list,fold_wrong_predict,fold)\n","\n","    #calculate the average\n","    calculate_average(avg_train_acc_list, avg_val_acc_list, avg_recall_list, avg_precision_list, avg_f1_score_list, avg_TPR_list, avg_FPR_list, num_folds, result_path)\n","\n","    torch.cuda.empty_cache()\n","\n","\n","normal_data_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train/normal'\n","abnormal_data_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset/train/abnormal'\n","train_normal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/train/normal'\n","train_abnormal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/train/abnormal'\n","result_path = '/content/drive/My Drive/Deep_X_torch/result'\n","\n","train(normal_data_dir,abnormal_data_dir,train_normal_tensor_path,train_abnormal_tensor_path,result_path,5)"]},{"cell_type":"markdown","metadata":{"id":"0p-MalRCZLME"},"source":["#測試模型"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iKRb2fuSZPoc"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import os\n","import numpy as np\n","import torch.optim as optim\n","import torchvision.models as models\n","import matplotlib.pyplot as plt\n","import csv\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import ConcatDataset\n","from sklearn import datasets\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime\n","\n","class MyDataset(Dataset):\n","    def __init__(self, data_path):\n","        self.data_path = data_path\n","        self.class_to_idx = {'abnormal': 1, 'normal': 0}  # 定義類別名稱到類別索引的映射\n","        self.data = []\n","        self.filenames = []  # store filenames\n","        for filename in os.listdir(data_path):\n","            if filename.endswith('.pt'):\n","                tensor = torch.load(os.path.join(data_path, filename))\n","                if filename.split('_')[0] == 'normal':\n","                    label_idx = 0\n","                else:\n","                    label_idx = 1\n","                self.data.append((tensor, label_idx, filename))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        tensor, labels, filename = self.data[index]\n","        return tensor, labels, filename\n","\n","class CombinedDataset(ConcatDataset):\n","    def __init__(self, dataset1, dataset2):\n","        super().__init__([dataset1, dataset2])\n","\n","    def __getitem__(self, index):\n","        return super().__getitem__(index)\n","\n","    def __len__(self):\n","        return super().__len__()\n","\n","# 找尋最新的訓練結果\n","def find_train_result_path(result_path):\n","    file_names = os.listdir(result_path)\n","    train_result_path = None\n","    num_max = 0\n","    for file_name in file_names:\n","        if file_name.startswith(\"result_\"):\n","            num_str = file_name.split(\"_\")[1]\n","            num = int(num_str)\n","            if num > num_max:\n","                num_max = num\n","\n","    result_path = os.path.join(result_path,\"result_{}\".format(num_max))\n","    train_result_path = os.path.join(result_path,\"train_{}\".format(num_max))\n","    return train_result_path\n","\n","\n","# 建立資料夾顯示訓練結果\n","def mkdir_outcome(result_path):\n","    file_names = os.listdir(result_path)\n","    num_max = 0\n","    for file_name in file_names:\n","        if file_name.startswith(\"result_\"):\n","            num_str = file_name.split(\"_\")[1]\n","            num = int(num_str)\n","            if(num > num_max):\n","                num_max = num\n","    # make folder for train result\n","    result_path = os.path.join(result_path,\"result_{}\".format(num_max))\n","    result_path_test = os.path.join(result_path,\"test_{}\".format(num_max))\n","    os.makedirs(result_path,exist_ok=True)\n","    os.makedirs(result_path_test,exist_ok=True)\n","    return result_path_test\n","\n","\n","# 模型評估指標\n","def test_index(conf_matrix):\n","    # Confusion Matrix to calculate [accuracy,precision,recall]\n","    precision = 0.0\n","    recall = 0.0\n","    f1_score = 0.0\n","    if((conf_matrix[0][0] + conf_matrix[0][1]) != 0):\n","        precision = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[0][1])\n","    if((conf_matrix[0][0] + conf_matrix[1][0]) != 0):\n","        recall = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[1][0])\n","    if((precision + recall) != 0):\n","        f1_score = 2*precision*recall / (precision + recall)\n","    TPR = recall\n","    FPR = conf_matrix[0][1] / (conf_matrix[0][1] + conf_matrix[1][1])\n","    print(\"\\t      Precision: {:<.4f}  -  Recall: {:<.4f}  -  F1 Score: {:<.4f}\".format(precision,recall,f1_score))\n","    return precision,recall,f1_score,TPR,FPR\n","\n","\n","# 混淆矩陣\n","def Confusion_Matrix(result_path,conf_matrix):\n","    # Create the 'confusion_matrix_record' directory if it doesn't exist\n","    confusion_matrix_record_dir = os.path.join(result_path, 'confusion_matrix_record')\n","    plt.clf()\n","    if not os.path.exists(confusion_matrix_record_dir):\n","        os.makedirs(confusion_matrix_record_dir)\n","\n","    confusion_matrix = np.array([[conf_matrix[0][0], conf_matrix[0][1]], [conf_matrix[1][0], conf_matrix[1][1]]])\n","    print(\"Confusion matrix:\")\n","    print(conf_matrix)\n","    plt.imshow(confusion_matrix, cmap=plt.cm.Blues, interpolation='nearest')\n","    plt.colorbar()\n","\n","    # confusion matrix index 各個 index 的數值\n","    for i in range(2):\n","        for j in range(2):\n","            text_color = 'black' if confusion_matrix[i][j] < 0.5 * confusion_matrix.max() else 'white'\n","            plt.annotate(str(confusion_matrix[i][j]), xy=(j, i), ha='center', va='center', color=text_color)\n","    tick_marks = np.arange(2)\n","    plt.xticks(tick_marks, ['Positive', 'Negative'])\n","    plt.yticks(tick_marks, ['Positive', 'Negative'])\n","    plt.ylabel('Predicted Label')\n","    plt.xlabel('True Label')\n","    plt.title('Confusion Matrix')\n","    result_path = result_path + '/confusion_matrix_record'\n","    plt.savefig(os.path.join(result_path,'test_confusion_matrix.png'))\n","\n","\n","# ROC曲線\n","def ROC_Curve(result_path,tpr_list,fpr_list):\n","    # Create the 'roc_curve_record' directory if it doesn't exist\n","    roc_curve_record_dir = os.path.join(result_path, 'roc_curve_record')\n","    if not os.path.exists(roc_curve_record_dir):\n","        os.makedirs(roc_curve_record_dir)\n","\n","    # 計算 AUC\n","    roc_auc = np.trapz(tpr_list, fpr_list)\n","\n","    # 繪製 ROC 曲線\n","    plt.clf()\n","    plt.plot(fpr_list, tpr_list, lw=1, label='ROC (AUC = %0.2f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], '--', color='gray', label='Random Guessing')\n","    plt.xlim([-0.05, 1.05])\n","    plt.ylim([-0.05, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend()\n","    result_path = result_path + '/roc_curve_record'\n","    plt.savefig(os.path.join(result_path,'test_Roc_curve.png'))\n","\n","\n","# 輸出每一次 epoch 的結果\n","def CSV_Output(test_result_path,param,num_epochs,test_loss_list,test_acc_list,precision_list,recall_list,TPR_list,FPR_list,f1_score_list,final_wrong_predict):\n","    # Create the 'csv_record' directory if it doesn't exist\n","    csv_record_dir = os.path.join(test_result_path, 'csv_record')\n","    if not os.path.exists(csv_record_dir):\n","        os.makedirs(csv_record_dir)\n","    with open(test_result_path + '/csv_record/test_epoch.csv','w',newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['num_epochs','batch_size','learning_rate','num_classes','device','start_time','end_time'])\n","        writer.writerow(param)\n","        writer.writerow('')\n","        writer.writerow(['Epoch','test_loss','test_acc','precision','recall','TPR','FPR','F1 score'])\n","        for epoch in range(num_epochs):\n","            writer.writerow([epoch + 1,\n","                            round(test_loss_list[epoch], 4),\n","                            round(test_acc_list[epoch].item(), 4),\n","                            round(precision_list[epoch], 4),\n","                            round(recall_list[epoch], 4),\n","                            round(TPR_list[epoch], 4),\n","                            round(FPR_list[epoch], 4),\n","                            round(f1_score_list[epoch], 4)])\n","        writer.writerow([f'wrong predict:',final_wrong_predict])\n","    print('CSV output Sucessfully')\n","\n","def test(test_normal_tensor_path,test_abnormal_tensor_path,result_path,fold):\n","    #超參數設定\n","    batch_size = 1\n","    learning_rate = 0.001\n","    num_epochs = 20\n","    num_classes = 2\n","    start_time = datetime.now()\n","    end_time = 0\n","    conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n","\n","    # Get the dataset\n","    test_normal_dataset = MyDataset(test_normal_tensor_path)\n","    test_abnormal_dataset = MyDataset(test_abnormal_tensor_path)\n","\n","    # Combine the datasets\n","    test_dataset = CombinedDataset(test_normal_dataset,test_abnormal_dataset)\n","\n","    #印出資料集大小\n","    print(\"dataset's size : \" + str(len(test_dataset)))\n","\n","    #創建模型\n","    model = models.resnet152(pretrained=False)\n","    model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    #print(model)\n","    #print(model.fc)\n","\n","    #將模型移動到GPU上進行運算\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    model.fc.to(device)\n","    print(\"Device used : \" + str(device))\n","\n","    #定義損失函數和優化器\n","    m = nn.Sigmoid()\n","    criterion = nn.BCELoss()\n","    # criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","    test_loss_list = []\n","    test_acc_list = []\n","    recall_list = []\n","    precision_list = []\n","    f1_score_list = []\n","    TPR_list = []\n","    FPR_list = []\n","    wrong_predict = []\n","    final_wrong_predict = []\n","\n","    # make dir to save the training outcome\n","    test_result_path = mkdir_outcome(result_path)\n","    print('test_result_path : ' + str(test_result_path))\n","\n","    train_result_path = find_train_result_path(result_path)\n","    print('train_result_path : ' + str(train_result_path))\n","\n","    for folds in range (0,fold):\n","      # 載入訓練好的模型參數\n","      model.load_state_dict(torch.load(os.path.join(train_result_path, \"train_fold\"+f'{folds+1}'+\".pt\")))\n","\n","      test_loader = DataLoader(test_dataset, batch_size, shuffle=True, num_workers=4)\n","\n","      #測試模型\n","      for epoch in range(num_epochs):\n","          test_loss = 0\n","          test_corrects = 0\n","          test_acc = 0\n","          model.load_state_dict(torch.load(os.path.join(train_result_path, \"train_fold\"+f'{folds+1}'+\".pt\")))\n","\n","          model.eval()\n","\n","          #初始化\n","          conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n","\n","          print(\"[Test Progress]: \")\n","          for inputs, labels, filename in tqdm(test_loader):\n","              targets=torch.eye(2)[labels.long(), :]\n","              inputs = inputs.to(device)\n","              labels = labels.to(device)\n","              targets = targets.to(device)\n","              with torch.set_grad_enabled(False):\n","                  outputs = model(inputs.to(device))\n","                  loss = criterion(m(outputs),targets.float())\n","              test_loss += loss.item() * inputs.size(0)\n","              _, preds = torch.max(outputs, 1)\n","              test_corrects += torch.sum(preds == labels.data)\n","\n","              # Count Confusion Matrix\n","              for t, p in zip(preds.view(-1), labels.view(-1)):\n","                  conf_matrix[t.long(), p.long()] += 1\n","                  if t != p:\n","                    wrong_predict.append(filename)\n","          test_loss =  test_loss / len(test_loader.dataset)\n","          test_acc =  test_corrects.double() / len(test_loader.dataset)\n","          test_loss_list.append(test_loss)\n","\n","          scheduler.step()\n","          end_time = datetime.now()\n","          print('\\nEpoch: [{}/{}]  test_loss: {:<.4f}  -  test_accuracy: {:<.4f}  -  test_correct: {:<10}'.format(\n","              epoch+1, num_epochs, test_loss, test_acc, test_corrects))\n","          print('wrong predicts : ' + str(wrong_predict))\n","\n","\n","          # teat index (評估指標)\n","          precision,recall,f1_score,TPR,FPR = test_index(conf_matrix)\n","\n","          # record the outcomes\n","          test_acc_list.append(test_acc),precision_list.append(precision),recall_list.append(recall)\n","          f1_score_list.append(f1_score),TPR_list.append(TPR),FPR_list.append(FPR)\n","\n","          if epoch + 1 == num_epochs:\n","            final_wrong_predict.append(wrong_predict)\n","          else:\n","            wrong_predict.clear()\n","\n","      # function of confusion matrix param(folder path, matrix, test normal dataset length, test unnormal dataset length)\n","      Confusion_Matrix(test_result_path,conf_matrix)\n","      # functio to show ROC curve\n","      ROC_Curve(test_result_path,TPR_list,FPR_list)\n","      # CSV visualization\n","      param = [num_epochs,batch_size,learning_rate,num_classes,device,start_time,end_time]\n","      CSV_Output(test_result_path,param,num_epochs,test_loss_list,test_acc_list,precision_list,recall_list,TPR_list,FPR_list,f1_score_list,final_wrong_predict)\n","\n","      confusion_matrix = np.array([[conf_matrix[0][0], conf_matrix[0][1]], [conf_matrix[1][0], conf_matrix[1][1]]])\n","      print(\"Confusion matrix:\")\n","      print(conf_matrix)\n","      plt.clf()\n","      plt.imshow(confusion_matrix, cmap=plt.cm.Blues, interpolation='nearest')\n","      plt.colorbar()\n","      tick_marks = np.arange(2)\n","      plt.xticks(tick_marks, ['Positive', 'Negative'])\n","      plt.yticks(tick_marks, ['Positive', 'Negative'])\n","      plt.ylabel('Predicted Label')\n","      plt.xlabel('True Label')\n","      plt.title('Confusion Matrix({})'.format(len(test_dataset)))\n","      plt.show()\n","\n","      torch.cuda.empty_cache()\n","\n","\n","test_normal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/test/normal'\n","test_abnormal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/test/abnormal'\n","result_path = '/content/drive/My Drive/Deep_X_torch/result'\n","\n","test(test_normal_tensor_path,test_abnormal_tensor_path,result_path,5)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EnWTcuTMlr5O"},"source":["#測試模型(SEResNet)"]},{"cell_type":"code","source":["!pip install timm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ceO70P1ms0UX","executionInfo":{"status":"ok","timestamp":1697303615930,"user_tz":-480,"elapsed":14525,"user":{"displayName":"陳均葦","userId":"12397795912524578037"}},"outputId":"6bbf6e4e-ce77-40ae-e74a-daae8ebee705"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.7)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (17.0.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Ow5kdZGl2hn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import os\n","import numpy as np\n","import torch.optim as optim\n","import torchvision.models as models\n","import matplotlib.pyplot as plt\n","import csv\n","import timm\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import ConcatDataset\n","from sklearn import datasets\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime\n","\n","class MyDataset(Dataset):\n","    def __init__(self, data_path):\n","        self.data_path = data_path\n","        self.class_to_idx = {'abnormal': 1, 'normal': 0}  # 定義類別名稱到類別索引的映射\n","        self.data = []\n","        self.filenames = []  # store filenames\n","        for filename in os.listdir(data_path):\n","            if filename.endswith('.pt'):\n","                tensor = torch.load(os.path.join(data_path, filename))\n","                if filename.split('_')[0] == 'normal':\n","                    label_idx = 0\n","                else:\n","                    label_idx = 1\n","                self.data.append((tensor, label_idx, filename))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        tensor, labels, filename = self.data[index]\n","        return tensor, labels, filename\n","\n","class CombinedDataset(ConcatDataset):\n","    def __init__(self, dataset1, dataset2):\n","        super().__init__([dataset1, dataset2])\n","\n","    def __getitem__(self, index):\n","        return super().__getitem__(index)\n","\n","    def __len__(self):\n","        return super().__len__()\n","\n","# 找尋最新的訓練結果\n","def find_train_result_path(result_path):\n","    file_names = os.listdir(result_path)\n","    train_result_path = None\n","    num_max = 0\n","    for file_name in file_names:\n","        if file_name.startswith(\"result_\"):\n","            num_str = file_name.split(\"_\")[1]\n","            num = int(num_str)\n","            if num > num_max:\n","                num_max = num\n","\n","    result_path = os.path.join(result_path,\"result_{}\".format(num_max))\n","    train_result_path = os.path.join(result_path,\"train_{}\".format(num_max))\n","    return train_result_path\n","\n","\n","# 建立資料夾顯示訓練結果\n","def mkdir_outcome(result_path):\n","    file_names = os.listdir(result_path)\n","    num_max = 0\n","    for file_name in file_names:\n","        if file_name.startswith(\"result_\"):\n","            num_str = file_name.split(\"_\")[1]\n","            num = int(num_str)\n","            if(num > num_max):\n","                num_max = num\n","    # make folder for train result\n","    result_path = os.path.join(result_path,\"result_{}\".format(num_max))\n","    result_path_test = os.path.join(result_path,\"test_{}\".format(num_max))\n","    os.makedirs(result_path,exist_ok=True)\n","    os.makedirs(result_path_test,exist_ok=True)\n","    return result_path_test\n","\n","\n","# 模型評估指標\n","def test_index(conf_matrix):\n","    # Confusion Matrix to calculate [accuracy,precision,recall]\n","    precision = 0.0\n","    recall = 0.0\n","    f1_score = 0.0\n","    if((conf_matrix[0][0] + conf_matrix[0][1]) != 0):\n","        precision = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[0][1])\n","    if((conf_matrix[0][0] + conf_matrix[1][0]) != 0):\n","        recall = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[1][0])\n","    if((precision + recall) != 0):\n","        f1_score = 2*precision*recall / (precision + recall)\n","    TPR = recall\n","    FPR = conf_matrix[0][1] / (conf_matrix[0][1] + conf_matrix[1][1])\n","    print(\"\\t      Precision: {:<.4f}  -  Recall: {:<.4f}  -  F1 Score: {:<.4f}\".format(precision,recall,f1_score))\n","    return precision,recall,f1_score,TPR,FPR\n","\n","\n","# 混淆矩陣\n","def Confusion_Matrix(result_path,conf_matrix,folds):\n","    # Create the 'confusion_matrix_record' directory if it doesn't exist\n","    confusion_matrix_record_dir = os.path.join(result_path, 'confusion_matrix_record'+'_fold'+f'{folds}')\n","    plt.clf()\n","    if not os.path.exists(confusion_matrix_record_dir):\n","        os.makedirs(confusion_matrix_record_dir)\n","\n","    confusion_matrix = np.array([[conf_matrix[0][0], conf_matrix[0][1]], [conf_matrix[1][0], conf_matrix[1][1]]])\n","    print(\"Confusion matrix:\")\n","    print(conf_matrix)\n","    plt.imshow(confusion_matrix, cmap=plt.cm.Blues, interpolation='nearest')\n","    plt.colorbar()\n","\n","    # confusion matrix index 各個 index 的數值\n","    for i in range(2):\n","        for j in range(2):\n","            text_color = 'black' if confusion_matrix[i][j] < 0.5 * confusion_matrix.max() else 'white'\n","            plt.annotate(str(confusion_matrix[i][j]), xy=(j, i), ha='center', va='center', color=text_color)\n","    tick_marks = np.arange(2)\n","    plt.xticks(tick_marks, ['Positive', 'Negative'])\n","    plt.yticks(tick_marks, ['Positive', 'Negative'])\n","    plt.ylabel('Predicted Label')\n","    plt.xlabel('True Label')\n","    plt.title('Confusion Matrix')\n","    result_path = result_path + '/confusion_matrix_record'+'_fold'+f'{folds}'\n","    plt.savefig(os.path.join(result_path,'test_confusion_matrix.png'))\n","\n","\n","# ROC曲線\n","def ROC_Curve(result_path,tpr_list,fpr_list,folds):\n","    # Create the 'roc_curve_record' directory if it doesn't exist\n","    roc_curve_record_dir = os.path.join(result_path, 'roc_curve_record'+'_fold'+f'{folds}')\n","    if not os.path.exists(roc_curve_record_dir):\n","        os.makedirs(roc_curve_record_dir)\n","\n","    # 計算 AUC\n","    roc_auc = np.trapz(tpr_list, fpr_list)\n","\n","    # 繪製 ROC 曲線\n","    plt.clf()\n","    plt.plot(fpr_list, tpr_list, lw=1, label='ROC (AUC = %0.2f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], '--', color='gray', label='Random Guessing')\n","    plt.xlim([-0.05, 1.05])\n","    plt.ylim([-0.05, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend()\n","    result_path = result_path + '/roc_curve_record'+'_fold'+f'{folds}'\n","    plt.savefig(os.path.join(result_path,'test_Roc_curve.png'))\n","\n","\n","# 輸出每一次 epoch 的結果\n","def CSV_Output(test_result_path,param,num_epochs,test_loss_list,test_acc_list,precision_list,recall_list,TPR_list,FPR_list,f1_score_list,final_wrong_predict,folds):\n","    # Create the 'csv_record' directory if it doesn't exist\n","    csv_record_dir = os.path.join(test_result_path, 'csv_record'+'_fold'+f'{folds}')\n","    if not os.path.exists(csv_record_dir):\n","        os.makedirs(csv_record_dir)\n","    with open(csv_record_dir + '/test_epoch.csv','w',newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['num_epochs','batch_size','learning_rate','num_classes','device','start_time','end_time'])\n","        writer.writerow(param)\n","        writer.writerow('')\n","        writer.writerow(['Epoch','test_loss','test_acc','precision','recall','TPR','FPR','F1 score'])\n","        for epoch in range(num_epochs):\n","            writer.writerow([epoch + 1,\n","                            round(test_loss_list[epoch], 4),\n","                            round(test_acc_list[epoch].item(), 4),\n","                            round(precision_list[epoch], 4),\n","                            round(recall_list[epoch], 4),\n","                            round(TPR_list[epoch], 4),\n","                            round(FPR_list[epoch], 4),\n","                            round(f1_score_list[epoch], 4)])\n","        writer.writerow([f'wrong predict:',final_wrong_predict])\n","    print('CSV output Sucessfully')\n","\n","def test(test_normal_tensor_path,test_abnormal_tensor_path,result_path,fold):\n","    #超參數設定\n","    batch_size = 1\n","    learning_rate = 0.001\n","    num_epochs = 20\n","    num_classes = 2\n","    start_time = datetime.now()\n","    end_time = 0\n","    conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n","\n","    # Get the dataset\n","    test_normal_dataset = MyDataset(test_normal_tensor_path)\n","    test_abnormal_dataset = MyDataset(test_abnormal_tensor_path)\n","\n","    # Combine the datasets\n","    test_dataset = CombinedDataset(test_normal_dataset,test_abnormal_dataset)\n","\n","    #印出資料集大小\n","    print(\"dataset's size : \" + str(len(test_dataset)))\n","\n","    #創建模型\n","    # model = models.resnet152(pretrained=False)\n","    model = timm.create_model('seresnet152d', pretrained=False)\n","    model.fc = nn.Linear(model.fc.in_features, num_classes)\n","    #print(model)\n","    #print(model.fc)\n","\n","    #將模型移動到GPU上進行運算\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    model.fc.to(device)\n","    print(\"Device used : \" + str(device))\n","\n","    #定義損失函數和優化器\n","    m = nn.Sigmoid()\n","    criterion = nn.BCELoss()\n","    # criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","    test_loss_list = []\n","    test_acc_list = []\n","    recall_list = []\n","    precision_list = []\n","    f1_score_list = []\n","    TPR_list = []\n","    FPR_list = []\n","    wrong_predict = []\n","    final_wrong_predict = []\n","\n","    # make dir to save the training outcome\n","    test_result_path = mkdir_outcome(result_path)\n","    print('test_result_path : ' + str(test_result_path))\n","\n","    train_result_path = find_train_result_path(result_path)\n","    print('train_result_path : ' + str(train_result_path))\n","\n","    for folds in range(1,fold + 1):\n","\n","        print(\"train model:\"+\"train\"+f'_fold_{folds}'+\".pt\")\n","\n","        # 載入訓練好的模型參數\n","        model.load_state_dict(torch.load(os.path.join(train_result_path, \"train\"+f'_fold_{folds}'+\".pt\")))\n","        test_loader = DataLoader(test_dataset, batch_size, shuffle=True, num_workers=4)\n","\n","        #測試模型\n","        for epoch in range(num_epochs):\n","            test_loss = 0\n","            test_corrects = 0\n","            test_acc = 0\n","            model.load_state_dict(torch.load(os.path.join(train_result_path, \"train\"+f'_fold_{folds}'+\".pt\")))\n","            model.eval()\n","\n","            #初始化\n","            conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n","\n","            print(\"[Test Progress]: \")\n","            for inputs, labels, filename in tqdm(test_loader):\n","                targets=torch.eye(2)[labels.long(), :]\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                targets = targets.to(device)\n","                with torch.set_grad_enabled(False):\n","                    outputs = model(inputs.to(device))\n","                    loss = criterion(m(outputs),targets.float())\n","                test_loss += loss.item() * inputs.size(0)\n","                _, preds = torch.max(outputs, 1)\n","                test_corrects += torch.sum(preds == labels.data)\n","\n","                # Count Confusion Matrix\n","                for t, p in zip(preds.view(-1), labels.view(-1)):\n","                    conf_matrix[t.long(), p.long()] += 1\n","                    if t != p:\n","                      wrong_predict.append(filename)\n","            test_loss =  test_loss / len(test_loader.dataset)\n","            test_acc =  test_corrects.double() / len(test_loader.dataset)\n","            test_loss_list.append(test_loss)\n","\n","            scheduler.step()\n","            end_time = datetime.now()\n","            print('\\nEpoch: [{}/{}]  test_loss: {:<.4f}  -  test_accuracy: {:<.4f}  -  test_correct: {:<10}'.format(\n","                epoch+1, num_epochs, test_loss, test_acc, test_corrects))\n","            print('wrong predicts : ' + str(wrong_predict))\n","\n","\n","            # teat index (評估指標)\n","            precision,recall,f1_score,TPR,FPR = test_index(conf_matrix)\n","\n","            # record the outcomes\n","            test_acc_list.append(test_acc),precision_list.append(precision),recall_list.append(recall)\n","            f1_score_list.append(f1_score),TPR_list.append(TPR),FPR_list.append(FPR)\n","\n","            if epoch + 1 == num_epochs:\n","              final_wrong_predict.append(wrong_predict)\n","            else:\n","              wrong_predict.clear()\n","\n","        # function of confusion matrix param(folder path, matrix, test normal dataset length, test unnormal dataset length)\n","        Confusion_Matrix(test_result_path,conf_matrix,folds)\n","        # functio to show ROC curve\n","        ROC_Curve(test_result_path,TPR_list,FPR_list,folds)\n","        # CSV visualization\n","        param = [num_epochs,batch_size,learning_rate,num_classes,device,start_time,end_time]\n","        CSV_Output(test_result_path,param,num_epochs,test_loss_list,test_acc_list,precision_list,recall_list,TPR_list,FPR_list,f1_score_list,final_wrong_predict,folds)\n","\n","        confusion_matrix = np.array([[conf_matrix[0][0], conf_matrix[0][1]], [conf_matrix[1][0], conf_matrix[1][1]]])\n","        print(\"Confusion matrix:\")\n","        print(conf_matrix)\n","        plt.clf()\n","        plt.imshow(confusion_matrix, cmap=plt.cm.Blues, interpolation='nearest')\n","        plt.colorbar()\n","        tick_marks = np.arange(2)\n","        plt.xticks(tick_marks, ['Positive', 'Negative'])\n","        plt.yticks(tick_marks, ['Positive', 'Negative'])\n","        plt.ylabel('Predicted Label')\n","        plt.xlabel('True Label')\n","        plt.title('Confusion Matrix({})'.format(len(test_dataset)))\n","        plt.show()\n","\n","        torch.cuda.empty_cache()\n","\n","\n","test_normal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/test/normal'\n","test_abnormal_tensor_path = '/content/drive/My Drive/Deep_X_torch/tensor/test/abnormal'\n","result_path = '/content/drive/My Drive/Deep_X_torch/result'\n","\n","test(test_normal_tensor_path,test_abnormal_tensor_path,result_path,5)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"634j9AKwr_FQ"},"source":["#清除資料"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"OtldGDxYsDDk","executionInfo":{"status":"ok","timestamp":1697351809116,"user_tz":-480,"elapsed":286,"user":{"displayName":"陳均葦","userId":"12397795912524578037"}}},"outputs":[],"source":["import os\n","import torch\n","\n","def delete_file_under_path(path):\n","    for root, directories, files in os.walk(path):\n","        for file in files:\n","            os.remove(os.path.join(root, file))\n","\n","def delete_folder_under_path(path):\n","    for root, directories, files in os.walk(path, topdown=False):\n","        for directory in directories:\n","            folder_path = os.path.join(root, directory)\n","            os.rmdir(folder_path)\n","\n","normal_jpg_path = '/content/drive/My Drive/Deep_X_torch/original_dataset/normal/normal(.jpg)'\n","normal_label_path = '/content/drive/My Drive/Deep_X_torch/original_dataset/normal/normal_label'\n","abnormal_jpg_path = '/content/drive/My Drive/Deep_X_torch/original_dataset/abnormal/abnormal(.jpg)'\n","abnormal_label_path = '/content/drive/My Drive/Deep_X_torch/original_dataset/abnormal/abnormal_label'\n","processed_dir = '/content/drive/My Drive/Deep_X_torch/processed_dataset'\n","splitted_dir = '/content/drive/My Drive/Deep_X_torch/splitted_dataset'\n","tesor_path = '/content/drive/My Drive/Deep_X_torch/tensor'\n","result_path = '/content/drive/My Drive/Deep_X_torch/result/'\n","\n","torch.cuda.empty_cache()\n","\n","# delete_file_under_path(normal_jpg_path)\n","# delete_file_under_path(abnormal_jpg_path)\n","# delete_file_under_path(normal_label_path)\n","# delete_file_under_path(abnormal_label_path)\n","# delete_file_under_path(processed_dir)\n","# delete_file_under_path(splitted_dir)\n","# delete_file_under_path(tesor_path)\n","\n","# delete_file_under_path(result_path)\n","# delete_folder_under_path(result_path)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["n8YuhhVNSL48","Pd2urWFtRs2f","hsQhWruTS-HN","ZnUUgJ0iOtxE","kgU18ivPXfIq","UGOZzdmVR02k","2Z0QXaeMnBIu","mtkv4P6wKNkv","0p-MalRCZLME","EnWTcuTMlr5O","634j9AKwr_FQ"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8332479ee29e44808ad9087a6dee3ff0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4dd84d86e83442c293831d624d58520b","IPY_MODEL_25989db5badb4447836febf775bdf98a","IPY_MODEL_0b0fae6a8c284412a99b432c5ece2ae3"],"layout":"IPY_MODEL_91e0024f7f384360b57362312e077552"}},"4dd84d86e83442c293831d624d58520b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c10a49e1ff024037b1e2bfc423a560ca","placeholder":"​","style":"IPY_MODEL_ad767b5436214e81991e4ad1f568ed22","value":"model.safetensors: 100%"}},"25989db5badb4447836febf775bdf98a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cae6be83e66472983aae617544d86cf","max":268076984,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96a9fb7f1105473b825041a46d8b18c6","value":268076984}},"0b0fae6a8c284412a99b432c5ece2ae3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3582fa04bdfb45febdc04bb8681ad043","placeholder":"​","style":"IPY_MODEL_d371e6f1d85348d4acec6b1cf30cb9b2","value":" 268M/268M [00:08&lt;00:00, 37.8MB/s]"}},"91e0024f7f384360b57362312e077552":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c10a49e1ff024037b1e2bfc423a560ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad767b5436214e81991e4ad1f568ed22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cae6be83e66472983aae617544d86cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96a9fb7f1105473b825041a46d8b18c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3582fa04bdfb45febdc04bb8681ad043":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d371e6f1d85348d4acec6b1cf30cb9b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}